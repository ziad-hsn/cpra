{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to CPRA Documentation","text":"<p>CPRA Documentation</p> <ul> <li>1M+ concurrent health checks per cluster</li> <li>&lt;120ms remediation dispatch median</li> <li>99.95% SLO-backed event delivery</li> </ul>"},{"location":"#cpra-hero-title","title":"Operate at planetary scale with confident remediation.","text":"<p>Concurrent Pulse-Remediation-Alerting (CPRA) delivers ultra-low latency health checks, automated remediation, and resilient alerting pipelines tuned by queueing theory. Explore proven playbooks, deep architecture notes, and reference-grade APIs to master the platform.</p> Start the Quickstart Explore the Reference"},{"location":"#why-cpra","title":"Why CPRA","text":"<p>CPRA is a high-performance infrastructure monitoring system engineered for teams that demand both scale and precision.</p> <ul> <li>Data-Oriented ECS Core: Optimized memory layout drives cache-friendly execution across massive fleets.</li> <li>Independent Pulse / Intervention / Code Pipelines: Tune and isolate workloads without cross-impact.</li> <li>Scientifically Tuned SLOs: Worker pools scale dynamically using M/M/c queueing theory for predictable latency.</li> <li>Built for Extensibility: Compose remediation recipes, pluggable transports, and custom monitors with safety rails.</li> </ul>"},{"location":"#documentation-at-a-glance","title":"Documentation at a Glance","text":"Section Goal &amp; Purpose Ready-to-use starting points Tutorials Learning-oriented guides to ramp quickly. Quickstart, First Custom Monitor How-To Guides Problem-driven recipes for day-two operations. Deploy to Production, Performance Tuning &amp; SLOs Explanation Deep dives that unpack the why behind design choices. Architecture Overview, Queueing Theory for Scaling Reference Precise API and configuration surface area. Monitor Configuration Schema, API Reference"},{"location":"#core-concepts-of-v05","title":"Core Concepts of v0.5","text":"<ol> <li>Entity-Component-System (ECS): A cache-optimized data model that keeps contention low even at extreme concurrency.</li> <li>Three Independent Pipelines: Dedicated Pulse (health checks), Intervention (remediation), and Code (alerting) flows deliver fault isolation.</li> <li>Dynamic Worker Scaling: Queue-theory-derived autoscaling ensures SLO commitments during load spikes.</li> </ol> <p>Ready to dive deeper? Start with the Quickstart tutorial, or jump into the configuration reference when you are wiring CPRA into production.</p>"},{"location":"explanation/","title":"Explanation","text":"<p>Understanding-oriented conceptual discussions</p>"},{"location":"explanation/#available-guides","title":"Available Guides","text":"<p>This section contains explanation documentation following the Diataxis framework.</p> <p>Explanation documentation is understanding-oriented: - Clarify and illuminate a topic - Provide context and background - Discuss alternatives and opinions - Focus on understanding, not instruction</p>"},{"location":"explanation/#contents","title":"Contents","text":"<ul> <li>Example: architecture-overview.md</li> </ul>"},{"location":"explanation/architecture-overview/","title":"Architecture Overview: The ECS Core","text":"<p>CPRA's architecture is built on a high-performance, data-oriented design centered around the Entity-Component-System (ECS) pattern. This design choice is fundamental to CPRA's ability to scale to over a million concurrent monitors with minimal memory footprint and high throughput.</p>"},{"location":"explanation/architecture-overview/#1-entity-component-system-ecs","title":"1. Entity-Component-System (ECS)","text":"<p>CPRA uses the ECS pattern to separate data from behavior, a technique borrowed from high-performance game engines and adapted for infrastructure monitoring. This separation is key to achieving performance at scale.</p> Element Role in CPRA Technical Implementation Entity Represents a single, unique monitor (e.g., a service health check). A simple integer ID. Component Raw data and configuration associated with a monitor. Structs like <code>MonitorState</code>, <code>PulseConfig</code>, and <code>JobStorage</code>. System The logic that processes monitors (Entities) that have a specific set of data (Components). Functions like <code>BatchPulseSystem</code> and <code>BatchInterventionSystem</code>. <p>By storing component data in contiguous memory blocks, ECS ensures that the CPU's cache is used efficiently, allowing the system to process thousands of monitors in a single, fast loop.</p>"},{"location":"explanation/architecture-overview/#2-the-three-independent-pipelines","title":"2. The Three Independent Pipelines","text":"<p>Monitoring tasks are divided into three distinct, concurrent pipelines. This separation is a core design decision that provides fault isolation and allows each pipeline to be optimized for its specific workload.</p> <p></p> Pipeline Primary Function Triggered By Key Characteristic Pulse Detection (Health Checks) Scheduling system (based on <code>interval</code>). High volume, I/O-bound. Intervention Remediation (Automated Recovery) Pulse Pipeline failure (after <code>unhealthy_threshold</code>). Medium volume, requires reliability. Code Alerting (Notifications) Intervention failure or persistent Pulse failure. Low volume, requires guaranteed delivery. <p>Each pipeline operates with its own dedicated queue and worker pool. This means a backlog in the Code (alerting) pipeline will not slow down the critical Pulse (health check) pipeline.</p>"},{"location":"explanation/architecture-overview/#3-data-oriented-optimizations-for-scale","title":"3. Data-Oriented Optimizations for Scale","text":"<p>To support 1,000,000+ monitors, CPRA employs advanced memory and data handling techniques:</p> <ul> <li>Component Consolidation: Instead of many small components, core state is consolidated into components like <code>MonitorState</code>. This minimizes the number of unique Archetypes in the ECS world, which is a critical factor for iteration speed.</li> <li>String Interning: Common strings (like monitor names and check types) are stored once in a global pool. Monitors only store a pointer to the string, drastically reducing the memory overhead per monitor.</li> <li>Batch Processing: All Systems operate on large batches of Entities, which maximizes CPU cache utilization and minimizes function call overhead.</li> </ul>"},{"location":"explanation/architecture-overview/#4-dynamic-worker-scaling","title":"4. Dynamic Worker Scaling","text":"<p>The worker pools for each pipeline are not statically configured. They are dynamically sized based on M/M/c queueing theory to meet a user-defined Service Level Objective (SLO). This ensures that CPRA always provisions the optimal number of workers to handle the current load while guaranteeing that a high percentage of jobs (e.g., P95) are processed within a target latency.</p> <p>For a detailed explanation of the scaling mechanism, see the Queueing Theory for Scaling document.</p>"},{"location":"explanation/queueing-theory/","title":"Queueing Theory for Dynamic Scaling","text":"<p>One of CPRA's most advanced features is its ability to dynamically size its worker pools to meet a guaranteed Service Level Objective (SLO). This is achieved by applying principles from Queueing Theory, specifically the M/M/c model.</p>"},{"location":"explanation/queueing-theory/#the-mmc-queueing-model","title":"The M/M/c Queueing Model","text":"<p>The M/M/c model is a mathematical framework used to analyze a system with:</p> <ul> <li>M (Markovian Arrival): Job arrivals follow a Poisson process (random, independent arrivals).</li> <li>M (Markovian Service): Job service times follow an exponential distribution.</li> <li>c (Servers): A fixed number of parallel servers (workers).</li> </ul> <p>In CPRA's context:</p> <ul> <li>Jobs ($\\lambda$): The rate at which monitors are ready for processing (e.g., Pulse checks).</li> <li>Workers ($c$): The number of goroutines in the worker pool.</li> <li>Service Time ($\\mu$): The time it takes a single worker to complete a job (e.g., an HTTP check).</li> </ul> <p>The goal is to find the minimum number of workers ($c$) required to ensure that the probability of a job waiting longer than the defined SLO is below a certain tolerance (e.g., 5%).</p>"},{"location":"explanation/queueing-theory/#slo-driven-worker-sizing","title":"SLO-Driven Worker Sizing","text":"<p>CPRA uses the M/M/c model to calculate the optimal worker count based on the following inputs:</p> <ol> <li>Arrival Rate ($\\lambda$): Calculated from the total number of monitors and their check intervals.</li> <li>Service Rate ($\\mu$): Estimated from historical job execution times.</li> <li>Service Level Objective (SLO): The maximum acceptable latency (e.g., 100ms P95).</li> </ol>"},{"location":"explanation/queueing-theory/#the-allen-cunneen-approximation","title":"The Allen-Cunneen Approximation","text":"<p>Real-world monitoring tasks often do not perfectly fit the \"Markovian\" (exponential) service time assumption. To account for the variability in real-world workloads (e.g., network jitter, slow APIs), CPRA uses the Allen-Cunneen approximation (also known as the $M/G/c$ model approximation).</p> <p>This approximation introduces the Coefficient of Variation ($C_s$) for service time, allowing the model to handle more general service time distributions. This makes the dynamic scaling far more robust and accurate in a production environment.</p>"},{"location":"explanation/queueing-theory/#dynamic-scaling-in-practice","title":"Dynamic Scaling in Practice","text":"<ol> <li>Measurement: The system continuously measures the current job arrival rate ($\\lambda$) and the average service time ($\\mu$) for each pipeline.</li> <li>Calculation: The State Logger System feeds this data into the M/M/c model (with the Allen-Cunneen approximation) to calculate the required number of workers ($c_{required}$) to meet the SLO.</li> <li>Adjustment: The Dynamic Worker Pool adjusts its size (scaling up or down) to match $c_{required}$, ensuring resources are neither wasted nor insufficient.</li> </ol> <p>This intelligent, mathematically-grounded approach is what allows CPRA to guarantee performance targets even as the monitored environment and load fluctuate.</p>"},{"location":"explanation/queueing-theory/#next-steps","title":"Next Steps","text":"<ul> <li>Performance Tuning &amp; SLOs: Learn how to configure and tune the SLO targets for your environment.</li> <li>Monitor Configuration Schema: See where to define the <code>interval</code> and <code>timeout</code> that feed into the $\\lambda$ and $\\mu$ calculations.</li> </ul>"},{"location":"how-to/","title":"How to","text":"<p>Task-oriented guides for specific goals</p>"},{"location":"how-to/#available-guides","title":"Available Guides","text":"<p>This section contains how-to documentation following the Diataxis framework.</p> <p>How-To Guides are task-oriented and help users accomplish specific goals: - Solve specific problems - Assume some knowledge and experience - Provide a series of steps - Focus on results</p>"},{"location":"how-to/#contents","title":"Contents","text":"<ul> <li>Example: deploy-to-production.md</li> </ul>"},{"location":"how-to/common-tasks/","title":"Common Tasks","text":"<p>This guide provides step-by-step instructions for common tasks you might perform with the CPRA monitoring system.</p> <p>Before you start</p> <p>Complete the Getting Started walkthrough so that the binary, monitors YAML, and mock servers are already running from the <code>cpra/</code> directory.</p>"},{"location":"how-to/common-tasks/#system-overview","title":"System Overview","text":"<p>CPRA uses a three-pipeline architecture for processing monitors:</p> <p></p> <ul> <li>Pulse Pipeline: Executes health checks</li> <li>Intervention Pipeline: Performs automated remediation</li> <li>Code Pipeline: Sends alert notifications</li> </ul> <p>Each pipeline operates independently with its own queue and worker pool. For a detailed explanation of the architecture, see the Architecture Overview document.</p>"},{"location":"how-to/common-tasks/#how-to-create-a-custom-monitor","title":"How to Create a Custom Monitor","text":"<p>Goal: Define a new monitor in a YAML file to check a service.</p> <p>Prerequisites: - A running CPRA application (see Quick Start). - An endpoint to monitor.</p> <p>Steps:</p> <ol> <li> <p>Open your <code>monitors.yaml</code> file.</p> </li> <li> <p>Add a new monitor definition. This example defines a monitor that checks an HTTP endpoint every 30 seconds.</p> <pre><code>- name: \"my-service-health-check\"\n  pulse:\n    type: \"http\"\n    interval: \"30s\"\n    timeout: \"5s\"\n    http:\n      url: \"http://my-service.example.com/health\"\n      method: \"GET\"\n      headers:\n        - \"Content-Type: application/json\"\n      expected_status: 200\n</code></pre> </li> <li> <p>Restart the CPRA application to load the new monitor.</p> </li> </ol> <p>Troubleshooting: - Problem: Monitor not loading.   - Solution: Check the YAML syntax. Ensure all required fields are present. Check the application logs for parsing errors.</p>"},{"location":"how-to/common-tasks/#how-to-configure-the-controller","title":"How to Configure the Controller","text":"<p>Goal: Customize the controller's behavior, such as batch sizes and worker pool settings.</p> <p>Prerequisites: - A <code>main.go</code> file to initialize the controller. - Familiarity with <code>controller.DefaultConfig()</code> structure (review the API Reference).</p> <p>Steps:</p> <ol> <li> <p>Get the default configuration. <pre><code>config := controller.DefaultConfig()\n</code></pre></p> </li> <li> <p>Modify the configuration values. <pre><code>config.Debug = true\nconfig.BatchSize = 2000\n// Note: Worker pool settings apply to all queues (Pulse, Intervention, Code)\nconfig.WorkerConfig.MinWorkers = 10\nconfig.WorkerConfig.MaxWorkers = 100\n</code></pre></p> </li> <li> <p>Create the controller with the custom configuration. <pre><code>ctrl := controller.NewController(config)\n</code></pre></p> </li> </ol> <p>Troubleshooting:  - Problem: Performance is not as expected.   - Solution: Adjust the <code>WorkerConfig.MinWorkers</code> and <code>WorkerConfig.MaxWorkers</code> settings. Note that these settings apply to all three worker pools (Pulse, Intervention, Code) in the current implementation.</p>"},{"location":"how-to/common-tasks/#how-to-add-a-new-system-to-the-controller","title":"How to Add a New System to the Controller","text":"<p>Goal: Extend the functionality of the monitoring system by adding a custom processing system.</p> <p>Prerequisites: - Familiarity with the ECS architecture and the <code>github.com/mlange-42/ark</code> library. - A custom system that implements the <code>ark.System</code> interface.</p> <p>Steps:</p> <ol> <li> <p>Define your custom system. <pre><code>type MyCustomSystem struct {\n    // ... your system's fields\n}\n\nfunc (s *MyCustomSystem) Initialize(w *ecs.World) {\n    // ... initialization logic\n}\n\nfunc (s *MyCustomSystem) Update(w *ecs.World) {\n    // ... update logic, called on each tick\n}\n\nfunc (s *MyCustomSystem) Finalize(w *ecs.World) {\n    // ... cleanup logic\n}\n</code></pre></p> </li> <li> <p>Add the system to the controller's world. This requires modifying the <code>NewController</code> function or having a method to add systems. Assuming you have a way to access the world:</p> <pre><code>// In your main.go or a custom setup function\nctrl := controller.NewController(controller.DefaultConfig())\nworld := ctrl.GetWorld()\n\nmySystem := &amp;MyCustomSystem{}\nworld.AddSystem(mySystem)\n</code></pre> </li> </ol> <p>Troubleshooting: - Problem: System is not running.   - Solution: Ensure your system is added to the world before the controller's <code>Start()</code> method is called. Check for any panics or errors during the system's <code>Initialize</code> or <code>Update</code> methods.</p>"},{"location":"how-to/common-tasks/#how-to-use-the-queueing-system-for-custom-jobs","title":"How to Use the Queueing System for Custom Jobs","text":"<p>Goal: Leverage the built-in queueing and worker pool for your own custom background jobs.</p> <p>Prerequisites: - A running CPRA application. - A custom job type that you want to process.</p> <p>Steps:</p> <ol> <li> <p>Create a new queue. <pre><code>qConfig := queue.DefaultQueueConfig()\nqConfig.Name = \"my-custom-queue\"\nmyQueue, err := queue.NewQueue(qConfig)\nif err != nil {\n    log.Fatalf(\"Failed to create custom queue: %v\", err)\n}\n</code></pre></p> </li> <li> <p>Create a worker pool for the queue. <pre><code>wpConfig := queue.DefaultWorkerPoolConfig()\nlogger := log.New(os.Stdout, \"\", log.LstdFlags)\nmyPool, err := queue.NewDynamicWorkerPool(myQueue, wpConfig, logger)\nif err != nil {\n    log.Fatalf(\"Failed to create custom worker pool: %v\", err)\n}\nmyPool.Start()\ndefer myPool.DrainAndStop()\n</code></pre></p> </li> <li> <p>Define and enqueue a job. <pre><code>type MyJob struct {\n    Data string\n}\n\nfunc (j *MyJob) Execute() jobs.Result {\n    // ... process the job\n    fmt.Printf(\"Processing job with data: %s\\n\", j.Data)\n    return jobs.Result{Success: true}\n}\n\nmyQueue.Enqueue(&amp;MyJob{Data: \"some important data\"})\n</code></pre></p> </li> </ol> <p>Troubleshooting: - Problem: Jobs are not being processed.   - Solution: Make sure you have started the worker pool with <code>myPool.Start()</code>. Check that the queue is not full and that there are available workers.</p>"},{"location":"how-to/deploy-to-production/","title":"Deploy To Production","text":"<p>This guide covers production deployment options for CPRA: running a compiled binary, Docker containers, and basic Kubernetes notes. It assumes Go 1.25+ and a monitors YAML file.</p>"},{"location":"how-to/deploy-to-production/#prerequisites","title":"Prerequisites","text":"<ul> <li>Go 1.25+</li> <li>A monitors YAML file (for example <code>mock-servers/test_10k.yaml</code>)</li> <li>Optional: Docker (for containerized deployment)</li> </ul>"},{"location":"how-to/deploy-to-production/#option-a-deploy-the-compiled-binary","title":"Option A: Deploy the Compiled Binary","text":"<ol> <li> <p>Build a static binary:    <pre><code>cd cpra\ngo build -trimpath -ldflags \"-s -w\" -o cpra .\n</code></pre></p> </li> <li> <p>Copy the binary and your YAML file to the target host, then run:    <pre><code>./cpra --yaml /path/to/monitors.yaml\n</code></pre></p> </li> <li> <p>(Optional) Enable/disable profiling flags at runtime:    <pre><code>./cpra --yaml /path/to/monitors.yaml --pprof=true --pprof.addr localhost:6060\n</code></pre></p> </li> <li> <p>(Optional) systemd unit example:    <pre><code>[Unit]\nDescription=CPRA Monitoring\nAfter=network.target\n\n[Service]\nExecStart=/opt/cpra/cpra --yaml /opt/cpra/monitors.yaml --pprof=false\nRestart=always\nUser=cpra\nGroup=cpra\nLimitNOFILE=1048576\n\n[Install]\nWantedBy=multi-user.target\n</code></pre></p> </li> </ol>"},{"location":"how-to/deploy-to-production/#option-b-deploy-with-docker","title":"Option B: Deploy with Docker","text":"<ol> <li>Build the image:    <pre><code>docker build -f docker/Dockerfile -t cpra .\n</code></pre></li> </ol> <p>Note: If the build fails due to a missing <code>samples/</code> directory referenced in the Dockerfile, either create <code>cpra/samples</code> with your YAML files, or remove the <code>COPY samples samples</code> line from <code>docker/Dockerfile</code> before building.</p> <ol> <li> <p>Run with a mounted YAML file:    <pre><code>docker run -d --name cpra \\\n  -v $(pwd)/mock-servers/test_10k.yaml:/app/monitors.yaml:ro \\\n  --restart unless-stopped \\\n  cpra \\\n  ./cpra --yaml /app/monitors.yaml\n</code></pre></p> </li> <li> <p>Control logging and memory via env if needed:    <pre><code>docker run -d --name cpra \\\n  -e GOMEMLIMIT=1073741824 \\\n  -e GOGC=100 \\\n  -v $(pwd)/mock-servers/test_10k.yaml:/app/monitors.yaml:ro \\\n  cpra \\\n  ./cpra --yaml /app/monitors.yaml --debug\n</code></pre></p> </li> </ol>"},{"location":"how-to/deploy-to-production/#option-c-kubernetes-basic-outline","title":"Option C: Kubernetes (basic outline)","text":"<p>Use a Deployment with a ConfigMap or Secret for your YAML, and a small PVC if you want to persist logs.</p> <p>Example Deployment snippet: <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: cpra\nspec:\n  replicas: 1\n  selector:\n    matchLabels: { app: cpra }\n  template:\n    metadata:\n      labels: { app: cpra }\n    spec:\n      containers:\n        - name: cpra\n          image: cpra:latest\n          args: [\"./cpra\", \"--yaml\", \"/config/monitors.yaml\", \"--pprof=false\"]\n          volumeMounts:\n            - name: config\n              mountPath: /config\n              readOnly: true\n      volumes:\n        - name: config\n          configMap:\n            name: cpra-monitors\n</code></pre></p>"},{"location":"how-to/deploy-to-production/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>High memory usage: reduce worker max or queue capacity in code/config; consider <code>GOMEMLIMIT</code> and lower <code>GOGC</code>.</li> <li>No monitors loaded: confirm YAML path and file permissions; run with <code>--debug</code>.</li> <li>Slow processing: adjust <code>SizingServiceTime</code>, <code>SizingSLO</code>, and worker min/max in config.</li> </ul>"},{"location":"how-to/deploy-to-production/#related-guides","title":"Related Guides","text":"<ul> <li>Common Tasks</li> <li>API Reference</li> </ul>"},{"location":"how-to/performance-tuning/","title":"Performance Tuning and SLOs","text":"<p>CPRA's performance is driven by its ability to dynamically size its worker pools to meet a Service Level Objective (SLO). This guide explains how to configure and tune these settings for optimal performance in your environment.</p>"},{"location":"how-to/performance-tuning/#1-understanding-the-slo","title":"1. Understanding the SLO","text":"<p>The SLO in CPRA is defined as the target latency for job processing in each pipeline. By default, the target is 100ms P95, meaning 95% of all jobs should be processed within 100 milliseconds.</p> <p>The worker pool for each pipeline (Pulse, Intervention, Code) is independently sized to meet this SLO based on the principles of M/M/c queueing theory.</p>"},{"location":"how-to/performance-tuning/#2-configuring-the-global-controller","title":"2. Configuring the Global Controller","text":"<p>The primary configuration for performance tuning is done in the <code>ControllerConfig</code> struct when initializing CPRA.</p> Configuration Field Description Tuning Impact <code>SLOTargetMs</code> The target latency in milliseconds for P95 job completion. Lowering this value forces the system to provision more workers and can increase resource consumption. <code>WorkerConfig.MinWorkers</code> The minimum number of workers to keep active, even under no load. Prevents cold start latency. Set to a small number (e.g., 10). <code>WorkerConfig.MaxWorkers</code> The absolute maximum number of workers the pool can scale to. Acts as a safety limit to prevent resource exhaustion during extreme load spikes. <code>BatchSize</code> The number of entities processed by a System in a single iteration. Increasing this value can improve throughput but may increase the latency of individual state updates."},{"location":"how-to/performance-tuning/#3-tuning-the-pulse-pipeline","title":"3. Tuning the Pulse Pipeline","text":"<p>The Pulse pipeline is the most critical and highest-volume pipeline. Its performance is heavily influenced by the network latency of the health checks themselves.</p> <ul> <li>Monitor Interval (<code>interval</code>): A shorter interval increases the job arrival rate ($\\lambda$), which forces the worker pool to scale up.</li> <li>Monitor Timeout (<code>timeout</code>): A longer timeout increases the average service time ($\\mu$), which also forces the worker pool to scale up.</li> </ul> <p>Best Practice: Set the <code>timeout</code> to be as short as possible. A long timeout directly increases the service time, which is the most significant factor in the M/M/c calculation.</p>"},{"location":"how-to/performance-tuning/#4-monitoring-and-profiling","title":"4. Monitoring and Profiling","text":"<p>To validate your tuning efforts, use the built-in profiling tools:</p> <ol> <li>Enable Profiling: Start CPRA with the <code>--pprof</code> flag.</li> <li>Access Metrics: The profiling server will be available at <code>http://localhost:6060/debug/pprof/</code>.</li> <li>Analyze Worker Pool Metrics: Pay close attention to the <code>queue_size</code> and <code>worker_count</code> metrics exposed by the controller. If the <code>queue_size</code> is consistently high, it indicates that the worker pool is undersized for the current load and SLO target.</li> </ol> <p>Tip: If you observe high CPU utilization but low throughput, consider increasing the <code>BatchSize</code> to reduce system overhead. If you observe high latency, consider lowering the <code>SLOTargetMs</code> (if resources allow) or increasing the <code>MaxWorkers</code>.</p>"},{"location":"how-to/performance-tuning/#next-steps","title":"Next Steps","text":"<ul> <li>Queueing Theory for Dynamic Scaling: Understand the mathematical model behind the dynamic scaling.</li> <li>Monitor Configuration Schema: Review the configuration fields that affect job arrival and service rates.</li> </ul>"},{"location":"reference/","title":"Reference","text":"<p>Information-oriented technical descriptions</p>"},{"location":"reference/#available-guides","title":"Available Guides","text":"<p>This section contains reference documentation following the Diataxis framework.</p> <p>Reference documentation is information-oriented: - Describe the machinery - Be accurate and complete - Focus on describing, not explaining - Structure content for finding information</p>"},{"location":"reference/#contents","title":"Contents","text":"<ul> <li>Example: api-documentation.md</li> </ul>"},{"location":"reference/api-documentation/","title":"CLI &amp; Configuration Reference","text":"<p>This guide aggregates the knobs you use to run CPRA in production: command-line flags, YAML schema basics, environment variables, and container tips. Use it together with the API Reference when wiring CPRA into your own tooling.</p>"},{"location":"reference/api-documentation/#command-line-interface","title":"Command-Line Interface","text":"<p>The CPRA binary exposes a concise flag set. All flags are optional; sensible defaults exist so you can start quickly and override as needed.</p> Flag Type Default Description <code>--yaml</code> string <code>internal/loader/replicated_test.yaml</code> Path to the monitors YAML file. Override with your own config (for example <code>mock-servers/test_10k.yaml</code>). <code>--config</code> string empty Optional application config file if you externalize controller settings. <code>--debug</code> bool <code>false</code> Enables verbose logging and queue sizing diagnostics. <code>--pprof</code> bool <code>true</code> Toggles the embedded profiling server. Disable in locked-down environments. <code>--pprof.addr</code> string <code>localhost:6060</code> Listen address for the profiling server. <p>Profiling in production</p> <p>Keep <code>--pprof</code> enabled in staging so you can capture heap/CPU traces with <code>go tool pprof http://host:6060/debug/pprof/heap</code>. Disable (or firewall) the endpoint before exposing the binary to the internet.</p>"},{"location":"reference/api-documentation/#yaml-monitor-schema-quick-primer","title":"YAML Monitor Schema (Quick Primer)","text":"<p>Monitors live in a single YAML document under the <code>monitors</code> key. This lightweight schema mirrors the ECS component model. A minimal example:</p> <pre><code>monitors:\n  - name: \"edge-api-health\"\n    pulse_check:\n      type: http\n      interval: 30s\n      timeout: 5s\n      max_failures: 3\n      config:\n        method: GET\n        url: https://edge.example.com/health\n    intervention:\n      type: script\n      config:\n        script: /opt/cpra/scripts/restart-edge.sh\n    codes:\n      red:\n        dispatch: true\n        notify: pagerduty\n        config:\n          url: https://events.pagerduty.com/v2/enqueue\n</code></pre> <p>Key ideas:</p> <ol> <li>Pulse defines how to collect health (HTTP/TCP/ICMP/custom command).</li> <li>Intervention specifies the automated remediation handler.</li> <li>Codes let you map failure tiers to alert transports.</li> </ol> <p>For larger samples open <code>mock-servers/test_10k.yaml</code> or generate new datasets with <code>mock-servers/generate_monitors.py</code>.</p>"},{"location":"reference/api-documentation/#environment-variables","title":"Environment Variables","text":"<p>Environment variables complement CLI flags when you containerize CPRA.</p> Variable Purpose Typical Value <code>GOMEMLIMIT</code> Hard cap for Go\u2019s soft memory limit. Helps prevent OOM kills in containers. <code>1073741824</code> (1 GiB) <code>GOGC</code> Target heap growth percentage for GC. Lower values trigger more frequent collections. <code>100</code> (default), <code>50</code> for tighter control <code>CPRA_DEBUG</code> Enables debug logging without changing CLI flags in Docker Compose/systemd. <code>true</code>/<code>false</code> <code>YAML_FILE</code> Convenience variable used in <code>docker-compose</code> examples to point CPRA at a specific monitors file. <code>samples/replicated_test_10k.yaml</code> <p>Memory tuning</p> <p>When you shrink <code>GOMEMLIMIT</code>, also review <code>config.WorkerConfig.MaxWorkers</code> at runtime. Too many workers with a small memory budget can still crash the process even if Go tries to respect the limit.</p>"},{"location":"reference/api-documentation/#docker-container-tips","title":"Docker &amp; Container Tips","text":"<ol> <li>Build using the maintained multi-stage Dockerfile:    <pre><code>docker build -f docker/Dockerfile -t cpra:latest .\n</code></pre></li> <li>Mount monitor configs read-only so container restarts keep the same dataset:    <pre><code>docker run -d --name cpra \\\n  -v $(pwd)/mock-servers/test_10k.yaml:/app/monitors.yaml:ro \\\n  cpra:latest \\\n  ./cpra --yaml /app/monitors.yaml\n</code></pre></li> <li>Propagate env overrides with <code>-e GOMEMLIMIT=... -e CPRA_DEBUG=true</code>.</li> <li>Expose profiling only on localhost or behind a reverse proxy when <code>--pprof</code> stays enabled.</li> </ol>"},{"location":"reference/api-documentation/#deployment-checklist","title":"Deployment Checklist","text":"<ul> <li>\u2705 Verify <code>./cpra --yaml &lt;file&gt; --debug</code> locally before promoting configs.</li> <li>\u2705 Keep a copy of the exact YAML shipped to production (git or artifact storage).</li> <li>\u2705 Monitor queue metrics via <code>controller.PrintShutdownMetrics()</code> during canary runs.</li> <li>\u2705 Use the Deploy to Production guide for binary/Docker/Kubernetes recipes.</li> </ul> <p>With these references you can wire CPRA into automation pipelines without hunting through the top-level README.</p>"},{"location":"reference/api-reference/","title":"API Reference","text":"<p>This document provides comprehensive API reference documentation for all exported functions and types in the CPRA monitoring system.</p>"},{"location":"reference/api-reference/#package-internalcontroller","title":"Package: internal/controller","text":"<p>The controller package manages the ECS (Entity-Component-System) world and its systems using ark-tools (a Go ECS library from github.com/mlange-42/ark).</p> <p>Key Concepts: - Entity: A unique ID representing a monitor - Component: Data attached to entities (e.g., MonitorState, PulseConfig) - System: Logic that processes entities with specific components</p> <p></p> <p>For a comprehensive overview of the system architecture, see the Architecture Overview document.</p> <p>It orchestrates the entire application flow including initialization, monitoring, and lifecycle management.</p>"},{"location":"reference/api-reference/#functions","title":"Functions","text":""},{"location":"reference/api-reference/#defaultconfig-config","title":"DefaultConfig() Config","text":"<ul> <li>Purpose: Returns a default configuration for the Controller</li> <li>Parameters: None</li> <li>Returns: Config - A Config struct with sensible defaults</li> <li>Errors: None</li> <li>Example:   <pre><code>config := controller.DefaultConfig()\nconfig.Debug = true\nconfig.BatchSize = 2000\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#newcontrollerconfig-config-controller","title":"NewController(config Config) *Controller","text":"<ul> <li>Purpose: Creates a new controller with the refactored systems using ark-tools</li> <li>Parameters: </li> <li>config (Config) - Configuration for the controller including queue settings, worker pool config, and batch processing parameters</li> <li>Returns: *Controller - A fully initialized controller ready to load monitors and start processing</li> <li>Errors: Fatal errors logged if queue or worker pool creation fails</li> <li>Example:   <pre><code>config := controller.DefaultConfig()\nctrl := controller.NewController(config)\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#initializeloggersdebugmode-bool","title":"InitializeLoggers(debugMode bool)","text":"<ul> <li>Purpose: Initializes all system loggers with the specified debug mode. Must be called before using the controller to set up package-level loggers (SystemLogger, SchedulerLogger, etc.)</li> <li>Parameters:</li> <li>debugMode (bool) - Whether to enable debug-level logging</li> <li>Returns: None</li> <li>Errors: None</li> <li>Example:   <pre><code>controller.InitializeLoggers(true)  // Call this first, before NewController\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#closeloggers","title":"CloseLoggers()","text":"<ul> <li>Purpose: Closes all system loggers and flushes buffered log entries. Should be called on application shutdown (typically with defer)</li> <li>Parameters: None</li> <li>Returns: None</li> <li>Errors: None</li> <li>Example:   <pre><code>defer controller.CloseLoggers()  // Ensures logs are flushed on exit\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#initializetracersenabled-bool","title":"InitializeTracers(enabled bool)","text":"<ul> <li>Purpose: Initializes distributed tracing for all components</li> <li>Parameters: </li> <li>enabled (bool) - Whether to enable tracing</li> <li>Returns: None</li> <li>Errors: None</li> <li>Example:   <pre><code>controller.InitializeTracers(true)\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#startperiodiccleanupinterval-maxage-timeduration","title":"StartPeriodicCleanup(interval, maxAge time.Duration)","text":"<ul> <li>Purpose: Starts periodic cleanup of old trace spans to prevent memory leaks</li> <li>Parameters: </li> <li>interval (time.Duration) - How often to run cleanup</li> <li>maxAge (time.Duration) - Maximum age of spans to retain</li> <li>Returns: None</li> <li>Errors: None</li> <li>Example:   <pre><code>controller.StartPeriodicCleanup(5*time.Minute, 30*time.Minute)\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#newloggercomponent-string-debugmode-bool-logger","title":"NewLogger(component string, debugMode bool) *Logger","text":"<ul> <li>Purpose: Creates a new logger for a specific component</li> <li>Parameters: </li> <li>component (string) - Name of the component for log prefixing</li> <li>debugMode (bool) - Whether to enable debug-level logging</li> <li>Returns: *Logger - A configured logger instance</li> <li>Errors: None</li> <li>Example:   <pre><code>logger := controller.NewLogger(\"MyComponent\", false)\nlogger.Info(\"Component initialized\")\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#newmemorymanagermaxmemorygb-uint64-gcintervalseconds-int-memorymanager","title":"NewMemoryManager(maxMemoryGB uint64, gcIntervalSeconds int) *MemoryManager","text":"<ul> <li>Purpose: Creates a memory manager that monitors and controls application memory usage</li> <li>Parameters: </li> <li>maxMemoryGB (uint64) - Maximum memory in gigabytes before triggering GC</li> <li>gcIntervalSeconds (int) - Interval between GC cycles</li> <li>Returns: *MemoryManager - A configured memory manager</li> <li>Errors: None</li> <li>Example:   <pre><code>memMgr := controller.NewMemoryManager(8, 30)\nmemMgr.Start()\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#newmetricsaggregator-metricsaggregator","title":"NewMetricsAggregator() *MetricsAggregator","text":"<ul> <li>Purpose: Creates a metrics aggregator for collecting system performance metrics</li> <li>Parameters: None</li> <li>Returns: *MetricsAggregator - A new metrics aggregator instance</li> <li>Errors: None</li> <li>Example:   <pre><code>metrics := controller.NewMetricsAggregator()\nmetrics.RecordSystemMetric(\"pulse\", 100, 50*time.Millisecond)\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#newrecoverysystemmaxerrors-int-resetwindow-timeduration-recoverysystem","title":"NewRecoverySystem(maxErrors int, resetWindow time.Duration) *RecoverySystem","text":"<ul> <li>Purpose: Creates a recovery system that tracks errors and provides circuit breaker functionality</li> <li>Parameters: </li> <li>maxErrors (int) - Maximum errors before triggering recovery</li> <li>resetWindow (time.Duration) - Time window for error counting</li> <li>Returns: *RecoverySystem - A configured recovery system</li> <li>Errors: None</li> <li>Example:   <pre><code>recovery := controller.NewRecoverySystem(10, 1*time.Minute)\nif recovery.ShouldRecover() {\n    // Trigger recovery logic\n}\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#newtracercomponent-string-enabled-bool-tracer","title":"NewTracer(component string, enabled bool) *Tracer","text":"<ul> <li>Purpose: Creates a distributed tracer for a specific component</li> <li>Parameters: </li> <li>component (string) - Name of the component being traced</li> <li>enabled (bool) - Whether tracing is enabled</li> <li>Returns: *Tracer - A configured tracer instance</li> <li>Errors: None</li> <li>Example:   <pre><code>tracer := controller.NewTracer(\"PulseSystem\", true)\nspan := tracer.StartSpan(\"ProcessPulse\")\ndefer span.End()\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#controller-methods","title":"Controller Methods","text":""},{"location":"reference/api-reference/#controller-loadmonitorsctx-contextcontext-filename-string-error","title":"(*Controller) LoadMonitors(ctx context.Context, filename string) error","text":"<ul> <li>Purpose: Loads monitors using the streaming loader from a YAML or JSON file</li> <li>Parameters: </li> <li>ctx (context.Context) - Context for cancellation</li> <li>filename (string) - Path to the monitor configuration file</li> <li>Returns: error - Error if loading fails</li> <li>Errors: Returns error if file cannot be read, parsed, or entities cannot be created</li> <li>Example:   <pre><code>ctx := context.Background()\nerr := ctrl.LoadMonitors(ctx, \"monitors.yaml\")\nif err != nil {\n    log.Fatalf(\"Failed to load monitors: %v\", err)\n}\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#controller-start-error","title":"(*Controller) Start() error","text":"<ul> <li>Purpose: Begins the main processing loop of the controller</li> <li>Parameters: None</li> <li>Returns: error - Error if controller is already running</li> <li>Errors: Returns error if controller is already started</li> <li>Example:   <pre><code>if err := ctrl.Start(); err != nil {\n    log.Fatalf(\"Failed to start controller: %v\", err)\n}\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#controller-stop","title":"(*Controller) Stop()","text":"<ul> <li>Purpose: Gracefully shuts down the controller</li> <li>Parameters: None</li> <li>Returns: None</li> <li>Errors: None</li> <li>Example:   <pre><code>defer ctrl.Stop()\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#controller-getworld-ecsworld","title":"(Controller) GetWorld() ecs.World","text":"<ul> <li>Purpose: Returns the ECS world for external access (e.g., testing, debugging)</li> <li>Parameters: None</li> <li>Returns: *ecs.World - The underlying ECS world</li> <li>Errors: None</li> <li>Example:   <pre><code>world := ctrl.GetWorld()\nstats := world.Stats()\nfmt.Printf(\"Entities: %d\\n\", stats.Entities.Used)\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#controller-printshutdownmetrics","title":"(*Controller) PrintShutdownMetrics()","text":"<ul> <li>Purpose: Logs queue, worker pool, and world statistics at shutdown</li> <li>Parameters: None</li> <li>Returns: None</li> <li>Errors: None</li> <li>Example:   <pre><code>ctrl.PrintShutdownMetrics()\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#controller-checkentitycountandswitchqueue","title":"(*Controller) CheckEntityCountAndSwitchQueue()","text":"<ul> <li>Purpose: Monitors entity count and switches queues if threshold exceeded</li> <li>Parameters: None</li> <li>Returns: None</li> <li>Errors: None</li> <li>Example:   <pre><code>ctrl.CheckEntityCountAndSwitchQueue()\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#package-internalqueue","title":"Package: internal/queue","text":"<p>The queue package implements the worker pool and queue patterns that form the basis of the project's concurrency model.</p>"},{"location":"reference/api-reference/#functions_1","title":"Functions","text":""},{"location":"reference/api-reference/#newqueueconfig-queueconfig-queue-error","title":"NewQueue(config QueueConfig) (Queue, error)","text":"<ul> <li>Purpose: Creates a new queue based on the provided configuration</li> <li>Parameters: </li> <li>config (QueueConfig) - Configuration specifying queue type and parameters</li> <li>Returns: </li> <li>Queue - The created queue interface implementation</li> <li>error - Error if queue creation fails</li> <li>Errors: Returns error if configuration is invalid or queue cannot be initialized</li> <li>Example:   <pre><code>config := queue.DefaultQueueConfig()\nconfig.Type = queue.QueueTypeHybrid\nq, err := queue.NewQueue(config)\nif err != nil {\n    log.Fatalf(\"Failed to create queue: %v\", err)\n}\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#defaultqueueconfig-queueconfig","title":"DefaultQueueConfig() QueueConfig","text":"<ul> <li>Purpose: Returns the default queue configuration</li> <li>Parameters: None</li> <li>Returns: QueueConfig - A QueueConfig with sensible defaults</li> <li>Errors: None</li> <li>Example:   <pre><code>config := queue.DefaultQueueConfig()\nconfig.Name = \"myqueue\"\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#newdynamicworkerpoolq-queue-config-workerpoolconfig-logger-loglogger-dynamicworkerpool-error","title":"NewDynamicWorkerPool(q Queue, config WorkerPoolConfig, logger log.Logger) (DynamicWorkerPool, error)","text":"<ul> <li>Purpose: Creates a new dynamic worker pool that executes jobs from a queue</li> <li>Parameters: </li> <li>q (Queue) - The queue to consume jobs from</li> <li>config (WorkerPoolConfig) - Worker pool configuration</li> <li>logger (*log.Logger) - Logger for worker pool events</li> <li>Returns: </li> <li>*DynamicWorkerPool - The created worker pool</li> <li>error - Error if worker pool creation fails</li> <li>Errors: Returns error if ants pool cannot be created or configuration is invalid</li> <li>Example:   <pre><code>config := queue.DefaultWorkerPoolConfig()\npool, err := queue.NewDynamicWorkerPool(myQueue, config, logger)\nif err != nil {\n    log.Fatalf(\"Failed to create worker pool: %v\", err)\n}\npool.Start()\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#defaultworkerpoolconfig-workerpoolconfig","title":"DefaultWorkerPoolConfig() WorkerPoolConfig","text":"<ul> <li>Purpose: Returns a default configuration for the worker pool</li> <li>Parameters: None</li> <li>Returns: WorkerPoolConfig - A WorkerPoolConfig with sensible defaults</li> <li>Errors: None</li> <li>Example:   <pre><code>config := queue.DefaultWorkerPoolConfig()\nconfig.MinWorkers = 10\nconfig.MaxWorkers = 100\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#newresultrouterconfig-workerpoolconfig-logger-loglogger-resultrouter","title":"NewResultRouter(config WorkerPoolConfig, logger log.Logger) ResultRouter","text":"<ul> <li>Purpose: Creates a new result router with buffered channels</li> <li>Parameters: </li> <li>config (WorkerPoolConfig) - Configuration for result channel depths</li> <li>logger (*log.Logger) - Logger for routing events</li> <li>Returns: *ResultRouter - A configured result router</li> <li>Errors: None</li> <li>Example:   <pre><code>config := queue.DefaultWorkerPoolConfig()\nrouter := queue.NewResultRouter(config, logger)\ngo func() {\n    for results := range router.PulseResultChan {\n        // Process pulse results\n    }\n}()\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#mmcwaitlambda-mu-float64-c-int-ca-cs-float64-wq-w-float64-err-error","title":"MmcWait(lambda, mu float64, c int, ca, cs float64) (wq, w float64, err error)","text":"<ul> <li>Purpose: Calculates average wait times using queueing theory. This helps predict how many workers you need to meet latency targets. Returns Wq (queue wait time) and W (total time) for an M/M/c queue; if Ca,Cs &gt; 0, applies Allen\u2013Cunneen variability inflation</li> </ul> <p>Simplified: Given a job arrival rate and processing time, this tells you how long jobs will wait in the queue</p> <ul> <li>Parameters:</li> <li>lambda (float64) - Arrival rate (jobs/sec) - how fast jobs arrive</li> <li>mu (float64) - Service rate per server (jobs/sec) - how fast one worker processes jobs</li> <li>c (int) - Number of servers (workers)</li> <li>ca (float64) - Coefficient of variation for arrivals (0 for exponential, use 0 if unsure)</li> <li>cs (float64) - Coefficient of variation for service (0 for exponential, use 0 if unsure)</li> <li>Returns:</li> <li>wq (float64) - Average waiting time in queue (seconds)</li> <li>w (float64) - Average total time in system (seconds) = waiting + processing</li> <li>err (error) - Error if system is unstable or parameters invalid</li> <li>Errors: Returns error if rho &gt;= 1 (unstable system - more jobs arriving than can be processed) or invalid parameters</li> <li>Example:   <pre><code>lambda := 100.0 // 100 jobs/sec\ntau := 0.02     // 20ms service time\nmu := 1.0 / tau\nc := 10         // 10 workers\nwq, w, err := queue.MmcWait(lambda, mu, c, 0, 0)\nif err != nil {\n    log.Printf(\"Queue unstable: %v\", err)\n}\nfmt.Printf(\"Wait time: %.3fs, Total time: %.3fs\\n\", wq, w)\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#findcforslolambda-tau-wtarget-ca-cs-float64-cmax-int-int-float64-error","title":"FindCForSLO(lambda, tau, wTarget, ca, cs float64, cMax int) (int, float64, error)","text":"<ul> <li>Purpose: Finds the minimum number of workers needed to meet your latency target (SLO = Service Level Objective)</li> </ul> <p>Simplified: \"I want jobs to complete in under 100ms - how many workers do I need?\"</p> <ul> <li>Parameters: </li> <li>lambda (float64) - Arrival rate (jobs/sec)</li> <li>tau (float64) - Service time per job (seconds)</li> <li>wTarget (float64) - Target total latency SLO (seconds)</li> <li>ca (float64) - Coefficient of variation for arrivals</li> <li>cs (float64) - Coefficient of variation for service</li> <li>cMax (int) - Maximum workers to search (0 for default 1M)</li> <li>Returns: </li> <li>int - Minimum number of workers needed</li> <li>float64 - Predicted wait time with that worker count</li> <li>error - Error if no solution found or invalid parameters</li> <li>Errors: Returns error if no worker count meets SLO within cMax</li> <li>Example:   <pre><code>lambda := 100.0           // 100 jobs/sec\ntau := 0.02               // 20ms service time\nwTarget := 0.1            // 100ms SLO\nc, w, err := queue.FindCForSLO(lambda, tau, wTarget, 0, 0, 1000)\nif err != nil {\n    log.Printf(\"Cannot meet SLO: %v\", err)\n}\nfmt.Printf(\"Need %d workers for %.3fs latency\\n\", c, w)\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#recommendcfromobservedqs-stats-wp-workerpoolstats-wqtarget-timeduration-ca-cs-float64-int-float64-error","title":"RecommendCFromObserved(qs Stats, wp WorkerPoolStats, wqTarget time.Duration, ca, cs float64) (int, float64, error)","text":"<ul> <li>Purpose: Computes a recommended worker count from observed queue and worker pool statistics</li> <li>Parameters: </li> <li>qs (Stats) - Queue statistics including arrival and service rates</li> <li>wp (WorkerPoolStats) - Worker pool statistics</li> <li>wqTarget (time.Duration) - Target queue wait time</li> <li>ca (float64) - Coefficient of variation for arrivals</li> <li>cs (float64) - Coefficient of variation for service</li> <li>Returns: </li> <li>int - Recommended worker count</li> <li>float64 - Predicted wait time</li> <li>error - Error if insufficient data or computation fails</li> <li>Errors: Returns error if no arrivals observed or insufficient throughput data</li> <li>Example:   <pre><code>qStats := myQueue.Stats()\nwpStats := myPool.Stats()\ntarget := 100 * time.Millisecond\nc, w, err := queue.RecommendCFromObserved(qStats, wpStats, target, 0, 0)\nif err == nil {\n    fmt.Printf(\"Recommend %d workers for %.3fs latency\\n\", c, w)\n}\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#queue-specific-constructors","title":"Queue-Specific Constructors","text":""},{"location":"reference/api-reference/#newadaptivequeuecapacity-uint64-adaptivequeue-error","title":"NewAdaptiveQueue(capacity uint64) (*AdaptiveQueue, error)","text":"<ul> <li>Purpose: Creates an adaptive queue that adjusts its behavior based on load</li> <li>Parameters: </li> <li>capacity (uint64) - Initial capacity (must be power of 2)</li> <li>Returns: </li> <li>*AdaptiveQueue - The created adaptive queue</li> <li>error - Error if capacity is invalid</li> <li>Errors: Returns error if capacity is not a power of 2</li> <li>Example:   <pre><code>q, err := queue.NewAdaptiveQueue(65536)\nif err != nil {\n    log.Fatalf(\"Failed to create adaptive queue: %v\", err)\n}\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#newworkivaqueuecapacity-int-queue","title":"NewWorkivaQueue(capacity int) Queue","text":"<ul> <li>Purpose: Creates a Workiva ring buffer based queue</li> <li>Parameters: </li> <li>capacity (int) - Queue capacity</li> <li>Returns: Queue - The created queue</li> <li>Errors: None</li> <li>Example:   <pre><code>q := queue.NewWorkivaQueue(32768)\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#newhybridqueueconfig-hybridqueueconfig-hybridqueue-error","title":"NewHybridQueue(config HybridQueueConfig) (*HybridQueue, error)","text":"<ul> <li>Purpose: Creates a hybrid queue combining ring buffer and heap with configurable drop policy</li> <li>Parameters: </li> <li>config (HybridQueueConfig) - Configuration including drop policy and capacities</li> <li>Returns: </li> <li>*HybridQueue - The created hybrid queue</li> <li>error - Error if configuration is invalid</li> <li>Errors: Returns error if ring capacity is not a power of 2</li> <li>Example:   <pre><code>config := queue.DefaultHybridQueueConfig()\nconfig.DropPolicy = queue.DropPolicyDropNewest\nq, err := queue.NewHybridQueue(config)\nif err != nil {\n    log.Fatalf(\"Failed to create hybrid queue: %v\", err)\n}\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#defaulthybridqueueconfig-hybridqueueconfig","title":"DefaultHybridQueueConfig() HybridQueueConfig","text":"<ul> <li>Purpose: Returns default configuration for hybrid queue</li> <li>Parameters: None</li> <li>Returns: HybridQueueConfig - Default hybrid queue configuration</li> <li>Errors: None</li> <li>Example:   <pre><code>config := queue.DefaultHybridQueueConfig()\nconfig.HeapCapacity = 100000\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#newboundedqueueconfig-boundedqueueconfig-boundedqueue","title":"NewBoundedQueue(config BoundedQueueConfig) *BoundedQueue","text":"<ul> <li>Purpose: Creates a bounded queue with fixed capacity</li> <li>Parameters: </li> <li>config (BoundedQueueConfig) - Configuration for the bounded queue</li> <li>Returns: *BoundedQueue - The created bounded queue</li> <li>Errors: None</li> <li>Example:   <pre><code>config := queue.BoundedQueueConfig{Capacity: 10000}\nq := queue.NewBoundedQueue(config)\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#dynamicworkerpool-methods","title":"DynamicWorkerPool Methods","text":""},{"location":"reference/api-reference/#dynamicworkerpool-start","title":"(*DynamicWorkerPool) Start()","text":"<ul> <li>Purpose: Begins the worker pool's operations</li> <li>Parameters: None</li> <li>Returns: None</li> <li>Errors: None</li> <li>Example:   <pre><code>pool.Start()\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#dynamicworkerpool-drainandstop","title":"(*DynamicWorkerPool) DrainAndStop()","text":"<ul> <li>Purpose: Waits for outstanding tasks to finish before stopping the worker pool</li> <li>Parameters: None</li> <li>Returns: None</li> <li>Errors: None</li> <li>Example:   <pre><code>pool.DrainAndStop()\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#dynamicworkerpool-getrouter-resultrouter","title":"(DynamicWorkerPool) GetRouter() ResultRouter","text":"<ul> <li>Purpose: Returns the result router for accessing type-specific result channels</li> <li>Parameters: None</li> <li>Returns: *ResultRouter - The result router instance</li> <li>Errors: None</li> <li>Example:   <pre><code>router := pool.GetRouter()\ngo processResults(router.PulseResultChan)\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#dynamicworkerpool-stats-workerpoolstats","title":"(*DynamicWorkerPool) Stats() WorkerPoolStats","text":"<ul> <li>Purpose: Returns runtime statistics for the worker pool</li> <li>Parameters: None</li> <li>Returns: WorkerPoolStats - Current worker pool statistics</li> <li>Errors: None</li> <li>Example:   <pre><code>stats := pool.Stats()\nfmt.Printf(\"Running: %d, Waiting: %d\\n\", stats.RunningWorkers, stats.WaitingTasks)\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#dynamicworkerpool-pause","title":"(*DynamicWorkerPool) Pause()","text":"<ul> <li>Purpose: Temporarily stops the worker pool from processing new tasks</li> <li>Parameters: None</li> <li>Returns: None</li> <li>Errors: None</li> <li>Example:   <pre><code>pool.Pause()\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#dynamicworkerpool-resume","title":"(*DynamicWorkerPool) Resume()","text":"<ul> <li>Purpose: Resumes worker pool processing after a pause</li> <li>Parameters: None</li> <li>Returns: None</li> <li>Errors: None</li> <li>Example:   <pre><code>pool.Resume()\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#dynamicworkerpool-replacequeuenewqueue-queue-error","title":"(*DynamicWorkerPool) ReplaceQueue(newQueue Queue) error","text":"<ul> <li>Purpose: Replaces the current queue with a new one for dynamic queue switching</li> <li>Parameters: </li> <li>newQueue (Queue) - The new queue to use</li> <li>Returns: error - Error if newQueue is nil</li> <li>Errors: Returns error if newQueue is nil</li> <li>Example:   <pre><code>newQueue, _ := queue.NewAdaptiveQueue(65536)\nerr := pool.ReplaceQueue(newQueue)\nif err != nil {\n    log.Printf(\"Failed to replace queue: %v\", err)\n}\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#package-internalcontrollercomponents","title":"Package: internal/controller/components","text":"<p>The components package defines the consolidated Entity-Component-System (ECS) components for the CPRA monitoring application.</p>"},{"location":"reference/api-reference/#types-and-methods","title":"Types and Methods","text":""},{"location":"reference/api-reference/#monitorstate","title":"MonitorState","text":"<p>MonitorState consolidates all monitor state into a single component with bitfield-based state management.</p> <p>State Check Methods:</p> <ul> <li>IsPulseNeeded() bool - Reports whether a pulse is needed for the monitor</li> <li>IsPulsePending() bool - Reports whether a pulse is currently pending</li> <li>IsPulseFirstCheck() bool - Reports whether this is the first pulse check</li> <li>IsInterventionNeeded() bool - Reports whether intervention is needed</li> <li>IsInterventionPending() bool - Reports whether intervention is pending</li> <li>IsCodeNeeded() bool - Reports whether code notification is needed</li> <li>IsCodePending() bool - Reports whether code notification is pending</li> </ul> <p>State Setter Methods:</p> <ul> <li>SetPulseNeeded(needed bool) - Sets whether a pulse is needed</li> <li>SetPulsePending(pending bool) - Sets whether a pulse is pending</li> <li>SetPulseFirstCheck(firstCheck bool) - Sets whether this is the first check</li> <li>SetInterventionNeeded(needed bool) - Sets whether intervention is needed</li> <li>SetInterventionPending(pending bool) - Sets whether intervention is pending</li> <li>SetCodeNeeded(needed bool) - Sets whether code notification is needed</li> <li>SetCodePending(pending bool) - Sets whether code notification is pending</li> </ul> <p>Example: <pre><code>state := &amp;components.MonitorState{\n    Name: \"web-server-01\",\n}\nstate.SetPulseNeeded(true)\nif state.IsPulseNeeded() {\n    // Schedule pulse check\n}\n</code></pre></p>"},{"location":"reference/api-reference/#pulseconfig","title":"PulseConfig","text":"<p>Copy() *PulseConfig - Creates a deep copy of the pulse configuration</p> <p>Example: <pre><code>pulseCfg := &amp;components.PulseConfig{\n    Type:     \"http\",\n    Interval: 60 * time.Second,\n    Timeout:  5 * time.Second,\n}\ncopy := pulseCfg.Copy()\n</code></pre></p>"},{"location":"reference/api-reference/#interventionconfig","title":"InterventionConfig","text":"<p>Copy() *InterventionConfig - Creates a deep copy of the intervention configuration</p>"},{"location":"reference/api-reference/#codeconfig","title":"CodeConfig","text":"<p>Copy() *CodeConfig - Creates a deep copy of the code configuration</p>"},{"location":"reference/api-reference/#jobstorage","title":"JobStorage","text":"<p>Copy() *JobStorage - Creates a deep copy of the job storage</p>"},{"location":"reference/api-reference/#package-internalloaderstreaming","title":"Package: internal/loader/streaming","text":"<p>The streaming package handles loading and parsing of monitor configuration files with streaming support for large files.</p>"},{"location":"reference/api-reference/#functions_2","title":"Functions","text":""},{"location":"reference/api-reference/#newstreamingloaderfilename-string-world-ecsworld-config-streamingconfig-streamingloader","title":"NewStreamingLoader(filename string, world ecs.World, config StreamingConfig) StreamingLoader","text":"<ul> <li>Purpose: Creates a new streaming loader for loading monitors from files</li> <li>Parameters: </li> <li>filename (string) - Path to the monitor configuration file</li> <li>world (*ecs.World) - The ECS world to create entities in</li> <li>config (StreamingConfig) - Streaming configuration</li> <li>Returns: *StreamingLoader - A configured streaming loader</li> <li>Errors: None</li> <li>Example:   <pre><code>config := streaming.DefaultStreamingConfig()\nloader := streaming.NewStreamingLoader(\"monitors.yaml\", world, config)\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#defaultstreamingconfig-streamingconfig","title":"DefaultStreamingConfig() StreamingConfig","text":"<ul> <li>Purpose: Returns optimized default configuration for large files</li> <li>Parameters: None</li> <li>Returns: StreamingConfig - Default streaming configuration</li> <li>Errors: None</li> <li>Example:   <pre><code>config := streaming.DefaultStreamingConfig()\nconfig.ParseBatchSize = 20000\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#newstreamingentitycreatorworld-ecsworld-config-entitycreationconfig-streamingentitycreator","title":"NewStreamingEntityCreator(world ecs.World, config EntityCreationConfig) StreamingEntityCreator","text":"<ul> <li>Purpose: Creates a new entity creator for batch entity creation</li> <li>Parameters: </li> <li>world (*ecs.World) - The ECS world</li> <li>config (EntityCreationConfig) - Entity creation configuration</li> <li>Returns: *StreamingEntityCreator - A configured entity creator</li> <li>Errors: None</li> <li>Example:   <pre><code>config := streaming.EntityCreationConfig{\n    BatchSize:   10000,\n    PreAllocate: 500000,\n}\ncreator := streaming.NewStreamingEntityCreator(world, config)\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#newstreamingjsonparserfilename-string-config-parseconfig-streamingjsonparser-error","title":"NewStreamingJsonParser(filename string, config ParseConfig) (*StreamingJsonParser, error)","text":"<ul> <li>Purpose: Creates a streaming JSON parser for large JSON files</li> <li>Parameters: </li> <li>filename (string) - Path to the JSON file</li> <li>config (ParseConfig) - Parser configuration</li> <li>Returns: </li> <li>*StreamingJsonParser - The created parser</li> <li>error - Error if file cannot be opened</li> <li>Errors: Returns error if file cannot be opened or read</li> <li>Example:   <pre><code>config := streaming.ParseConfig{BatchSize: 10000}\nparser, err := streaming.NewStreamingJsonParser(\"monitors.json\", config)\nif err != nil {\n    log.Fatalf(\"Failed to create parser: %v\", err)\n}\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#newstreamingyamlparserfilename-string-config-parseconfig-streamingyamlparser-error","title":"NewStreamingYamlParser(filename string, config ParseConfig) (*StreamingYamlParser, error)","text":"<ul> <li>Purpose: Creates a streaming YAML parser for large YAML files</li> <li>Parameters: </li> <li>filename (string) - Path to the YAML file</li> <li>config (ParseConfig) - Parser configuration</li> <li>Returns: </li> <li>*StreamingYamlParser - The created parser</li> <li>error - Error if file cannot be opened</li> <li>Errors: Returns error if file cannot be opened or read</li> <li>Example:   <pre><code>config := streaming.ParseConfig{BatchSize: 10000}\nparser, err := streaming.NewStreamingYamlParser(\"monitors.yaml\", config)\nif err != nil {\n    log.Fatalf(\"Failed to create parser: %v\", err)\n}\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#streamingloader-methods","title":"StreamingLoader Methods","text":""},{"location":"reference/api-reference/#streamingloader-loadctx-contextcontext-loadingstats-error","title":"(StreamingLoader) Load(ctx context.Context) (LoadingStats, error)","text":"<ul> <li>Purpose: Performs the complete streaming load operation</li> <li>Parameters: </li> <li>ctx (context.Context) - Context for cancellation</li> <li>Returns: </li> <li>*LoadingStats - Statistics about the loading operation</li> <li>error - Error if loading fails</li> <li>Errors: Returns error if parsing or entity creation fails</li> <li>Example:   <pre><code>ctx := context.Background()\nstats, err := loader.Load(ctx)\nif err != nil {\n    log.Fatalf(\"Failed to load: %v\", err)\n}\nfmt.Printf(\"Loaded %d monitors in %v\\n\", stats.TotalEntities, stats.LoadingTime)\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#streamingentitycreator-methods","title":"StreamingEntityCreator Methods","text":""},{"location":"reference/api-reference/#streamingentitycreator-processbatchesctx-contextcontext-batchchan-chan-monitorbatch-progresschan-chan-entityprogress-error","title":"(*StreamingEntityCreator) ProcessBatches(ctx context.Context, batchChan &lt;-chan MonitorBatch, progressChan chan&lt;- EntityProgress) error","text":"<ul> <li>Purpose: Processes monitor batches and creates entities</li> <li>Parameters: </li> <li>ctx (context.Context) - Context for cancellation</li> <li>batchChan (&lt;-chan MonitorBatch) - Channel receiving monitor batches</li> <li>progressChan (chan&lt;- EntityProgress) - Channel for progress updates</li> <li>Returns: error - Error if processing fails</li> <li>Errors: Returns error if entity creation fails</li> <li>Example:   <pre><code>err := creator.ProcessBatches(ctx, batchChan, progressChan)\nif err != nil {\n    log.Fatalf(\"Failed to process batches: %v\", err)\n}\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#streamingentitycreator-getstats-entitiescreated-int64-batchesprocessed-int64-rate-float64","title":"(*StreamingEntityCreator) GetStats() (entitiesCreated int64, batchesProcessed int64, rate float64)","text":"<ul> <li>Purpose: Returns current creation statistics</li> <li>Parameters: None</li> <li>Returns: </li> <li>entitiesCreated (int64) - Total entities created</li> <li>batchesProcessed (int64) - Total batches processed</li> <li>rate (float64) - Creation rate (entities/sec)</li> <li>Errors: None</li> <li>Example:   <pre><code>created, batches, rate := creator.GetStats()\nfmt.Printf(\"Created %d entities (%.0f/sec)\\n\", created, rate)\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#streamingentitycreator-pulserate-float64","title":"(*StreamingEntityCreator) PulseRate() float64","text":"<ul> <li>Purpose: Returns the aggregated expected pulse arrival rate (jobs/sec)</li> <li>Parameters: None</li> <li>Returns: float64 - Pulse arrival rate in jobs/sec</li> <li>Errors: None</li> <li>Example:   <pre><code>rate := creator.PulseRate()\nfmt.Printf(\"Expected pulse rate: %.2f jobs/sec\\n\", rate)\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#package-internalcontrollersystems","title":"Package: internal/controller/systems","text":"<p>The systems package contains the business logic that operates on entities and components within the ECS framework.</p>"},{"location":"reference/api-reference/#functions_3","title":"Functions","text":""},{"location":"reference/api-reference/#newbatchpulseschedulesystemworld-ecsworld-logger-logger-statelogger-statelogger-batchpulseschedulesystem","title":"NewBatchPulseScheduleSystem(world ecs.World, logger Logger, stateLogger StateLogger) *BatchPulseScheduleSystem","text":"<ul> <li>Purpose: Creates a system that schedules pulse checks based on monitor intervals</li> <li>Parameters: </li> <li>world (*ecs.World) - The ECS world</li> <li>logger (Logger) - System logger</li> <li>stateLogger (*StateLogger) - State change logger</li> <li>Returns: *BatchPulseScheduleSystem - The created system</li> <li>Errors: None</li> <li>Example:   <pre><code>system := systems.NewBatchPulseScheduleSystem(world, logger, stateLogger)\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#newbatchpulsesystemworld-ecsworld-q-queuequeue-batchsize-int-logger-logger-statelogger-statelogger-batchpulsesystem","title":"NewBatchPulseSystem(world ecs.World, q queue.Queue, batchSize int, logger Logger, stateLogger StateLogger) *BatchPulseSystem","text":"<ul> <li>Purpose: Creates a system that enqueues pulse jobs to the queue</li> <li>Parameters: </li> <li>world (*ecs.World) - The ECS world</li> <li>q (queue.Queue) - Queue to enqueue pulse jobs</li> <li>batchSize (int) - Maximum batch size for enqueueing</li> <li>logger (Logger) - System logger</li> <li>stateLogger (*StateLogger) - State change logger</li> <li>Returns: *BatchPulseSystem - The created system</li> <li>Errors: None</li> <li>Example:   <pre><code>system := systems.NewBatchPulseSystem(world, pulseQueue, 1000, logger, stateLogger)\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#newbatchpulseresultsystemworld-ecsworld-results-chan-jobsresult-logger-logger-statelogger-statelogger-batchpulseresultsystem","title":"NewBatchPulseResultSystem(world ecs.World, results &lt;-chan []jobs.Result, logger Logger, stateLogger StateLogger) *BatchPulseResultSystem","text":"<ul> <li>Purpose: Creates a system that processes pulse job results</li> <li>Parameters: </li> <li>world (*ecs.World) - The ECS world</li> <li>results (&lt;-chan []jobs.Result) - Channel receiving pulse results</li> <li>logger (Logger) - System logger</li> <li>stateLogger (*StateLogger) - State change logger</li> <li>Returns: *BatchPulseResultSystem - The created system</li> <li>Errors: None</li> <li>Example:   <pre><code>system := systems.NewBatchPulseResultSystem(world, resultChan, logger, stateLogger)\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#newbatchinterventionsystemworld-ecsworld-q-queuequeue-batchsize-int-logger-logger-statelogger-statelogger-batchinterventionsystem","title":"NewBatchInterventionSystem(world ecs.World, q queue.Queue, batchSize int, logger Logger, stateLogger StateLogger) *BatchInterventionSystem","text":"<ul> <li>Purpose: Creates a system that enqueues intervention jobs</li> <li>Parameters: </li> <li>world (*ecs.World) - The ECS world</li> <li>q (queue.Queue) - Queue to enqueue intervention jobs</li> <li>batchSize (int) - Maximum batch size</li> <li>logger (Logger) - System logger</li> <li>stateLogger (*StateLogger) - State change logger</li> <li>Returns: *BatchInterventionSystem - The created system</li> <li>Errors: None</li> <li>Example:   <pre><code>system := systems.NewBatchInterventionSystem(world, intQueue, 1000, logger, stateLogger)\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#newbatchinterventionresultsystemworld-ecsworld-results-chan-jobsresult-logger-logger-statelogger-statelogger-batchinterventionresultsystem","title":"NewBatchInterventionResultSystem(world ecs.World, results &lt;-chan []jobs.Result, logger Logger, stateLogger StateLogger) *BatchInterventionResultSystem","text":"<ul> <li>Purpose: Creates a system that processes intervention job results</li> <li>Parameters: </li> <li>world (*ecs.World) - The ECS world</li> <li>results (&lt;-chan []jobs.Result) - Channel receiving intervention results</li> <li>logger (Logger) - System logger</li> <li>stateLogger (*StateLogger) - State change logger</li> <li>Returns: *BatchInterventionResultSystem - The created system</li> <li>Errors: None</li> <li>Example:   <pre><code>system := systems.NewBatchInterventionResultSystem(world, resultChan, logger, stateLogger)\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#newbatchcodesystemworld-ecsworld-q-queuequeue-batchsize-int-logger-logger-statelogger-statelogger-batchcodesystem","title":"NewBatchCodeSystem(world ecs.World, q queue.Queue, batchSize int, logger Logger, stateLogger StateLogger) *BatchCodeSystem","text":"<ul> <li>Purpose: Creates a system that enqueues code notification jobs</li> <li>Parameters: </li> <li>world (*ecs.World) - The ECS world</li> <li>q (queue.Queue) - Queue to enqueue code jobs</li> <li>batchSize (int) - Maximum batch size</li> <li>logger (Logger) - System logger</li> <li>stateLogger (*StateLogger) - State change logger</li> <li>Returns: *BatchCodeSystem - The created system</li> <li>Errors: None</li> <li>Example:   <pre><code>system := systems.NewBatchCodeSystem(world, codeQueue, 1000, logger, stateLogger)\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#newbatchcoderesultsystemworld-ecsworld-results-chan-jobsresult-logger-logger-statelogger-statelogger-batchcoderesultsystem","title":"NewBatchCodeResultSystem(world ecs.World, results &lt;-chan []jobs.Result, logger Logger, stateLogger StateLogger) *BatchCodeResultSystem","text":"<ul> <li>Purpose: Creates a system that processes code notification job results</li> <li>Parameters: </li> <li>world (*ecs.World) - The ECS world</li> <li>results (&lt;-chan []jobs.Result) - Channel receiving code results</li> <li>logger (Logger) - System logger</li> <li>stateLogger (*StateLogger) - State change logger</li> <li>Returns: *BatchCodeResultSystem - The created system</li> <li>Errors: None</li> <li>Example:   <pre><code>system := systems.NewBatchCodeResultSystem(world, resultChan, logger, stateLogger)\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#newstateloggerdebugmode-bool-statelogger","title":"NewStateLogger(debugMode bool) *StateLogger","text":"<ul> <li>Purpose: Creates a state logger for tracking entity state transitions</li> <li>Parameters: </li> <li>debugMode (bool) - Whether to enable debug logging</li> <li>Returns: *StateLogger - A configured state logger</li> <li>Errors: None</li> <li>Example:   <pre><code>stateLogger := systems.NewStateLogger(true)\n</code></pre></li> </ul>"},{"location":"reference/api-reference/#newmemoryefficientsystemworld-ecsworld-config-memoryconfig-memoryefficientsystem","title":"NewMemoryEfficientSystem(world ecs.World, config MemoryConfig) MemoryEfficientSystem","text":"<ul> <li>Purpose: Creates a system for memory-efficient entity management</li> <li>Parameters: </li> <li>world (*ecs.World) - The ECS world</li> <li>config (MemoryConfig) - Memory management configuration</li> <li>Returns: *MemoryEfficientSystem - The created system</li> <li>Errors: None</li> <li>Example:   <pre><code>config := systems.MemoryConfig{MaxEntities: 1000000}\nsystem := systems.NewMemoryEfficientSystem(world, config)\n</code></pre></li> </ul>"},{"location":"reference/config-schema/","title":"Monitor Configuration Schema","text":"<p>The CPRA system is configured via a single YAML file that defines a list of monitors. This document provides a complete reference for the <code>Monitor</code> object schema.</p>"},{"location":"reference/config-schema/#top-level-monitor-object","title":"Top-Level Monitor Object","text":"Field Type Required Description <code>name</code> <code>string</code> Yes A unique, human-readable name for the monitor. <code>enabled</code> <code>boolean</code> No If <code>false</code>, the monitor is loaded but never scheduled. Defaults to <code>true</code>. <code>pulse</code> <code>PulseConfig</code> Yes Configuration for the health check pipeline. <code>intervention</code> <code>InterventionConfig</code> No Configuration for the automated remediation pipeline. <code>codes</code> <code>map[string]CodeConfig</code> No Configuration for the alerting pipeline, mapped by alert \"color\" (e.g., Red, Yellow)."},{"location":"reference/config-schema/#pulseconfig-health-check","title":"PulseConfig (Health Check)","text":"<p>Defines the parameters for the health check.</p> Field Type Required Description <code>type</code> <code>string</code> Yes The type of check: <code>http</code>, <code>tcp</code>, or <code>script</code>. <code>interval</code> <code>duration</code> Yes How often the check should run (e.g., <code>30s</code>, <code>5m</code>). <code>timeout</code> <code>duration</code> Yes Maximum time to wait for the check to complete (e.g., <code>5s</code>). <code>unhealthy_threshold</code> <code>integer</code> No Number of consecutive failures before the monitor is considered unhealthy and triggers Intervention. Defaults to <code>1</code>. <code>healthy_threshold</code> <code>integer</code> No Number of consecutive successes required to transition from unhealthy to healthy. Defaults to <code>1</code>. <code>config</code> <code>map[string]any</code> Yes Type-specific configuration (e.g., <code>http</code> details)."},{"location":"reference/config-schema/#config-examples","title":"<code>config</code> Examples","text":"<p>HTTP Check: <pre><code>config:\n  method: GET\n  url: https://api.example.com/health\n  headers:\n    - \"Authorization: Bearer token\"\n  expected_status: 200\n</code></pre></p> <p>TCP Check: <pre><code>config:\n  host: database.internal\n  port: 5432\n</code></pre></p>"},{"location":"reference/config-schema/#interventionconfig-remediation","title":"InterventionConfig (Remediation)","text":"<p>Defines the automated action to take when the <code>unhealthy_threshold</code> is met.</p> Field Type Required Description <code>action</code> <code>string</code> Yes The action to perform: <code>script</code> or <code>webhook</code>. <code>max_failures</code> <code>integer</code> No Maximum number of times to attempt the intervention before giving up and triggering the Code pipeline. Defaults to <code>1</code>. <code>config</code> <code>map[string]any</code> Yes Action-specific configuration."},{"location":"reference/config-schema/#config-example-script-action","title":"<code>config</code> Example (Script Action)","text":"<pre><code>config:\n  path: /usr/local/bin/restart_service.sh\n  args: [\"--force\", \"api-service\"]\n</code></pre>"},{"location":"reference/config-schema/#codeconfig-alerting","title":"CodeConfig (Alerting)","text":"<p>Defines the alerting policy. The map key (e.g., <code>Red</code>) is the name of the alert \"color\" or severity.</p> Field Type Required Description <code>dispatch</code> <code>string</code> Yes The trigger condition: <code>failure</code> (on Intervention failure) or <code>always</code> (on any Pulse failure). <code>notify</code> <code>string</code> Yes The notification method: <code>webhook</code>, <code>email</code>, or <code>slack</code>. <code>config</code> <code>map[string]any</code> Yes Notification-specific configuration."},{"location":"reference/config-schema/#config-example-webhook-notification","title":"<code>config</code> Example (Webhook Notification)","text":"<pre><code>config:\n  url: https://hooks.slack.com/services/T00000000/B00000000/XXX\n  payload:\n    text: \"Critical API is DOWN. Intervention failed.\"\n</code></pre>"},{"location":"reference/types-reference/","title":"Types Reference","text":"<p>This document provides detailed documentation for all exported types in the CPRA monitoring system.</p>"},{"location":"reference/types-reference/#package-internalcontroller","title":"Package: internal/controller","text":""},{"location":"reference/types-reference/#config","title":"Config","text":"<p>Configuration struct for the Controller.</p> <p>Fields: - Debug (bool) - Enable debug-level logging - StreamingConfig (streaming.StreamingConfig) - Configuration for streaming loader - QueueCapacity (uint64) - Initial queue capacity (must be power of 2) - WorkerConfig (queue.WorkerPoolConfig) - Worker pool configuration - BatchSize (int) - Batch size for system processing - UpdateInterval (time.Duration) - Update interval (deprecated, ark-tools TPS=100 controls timing) - SizingServiceTime (time.Duration) - \u03c4 (tau) - expected service time per job - SizingSLO (time.Duration) - W target - end-to-end latency SLO - SizingHeadroomPct (float64) - Safe headroom as fraction (e.g., 0.15 = 15%)</p> <p>Methods: - None (data struct)</p> <p>When to use: - When creating a new Controller instance - When customizing system behavior before initialization</p> <p>Example: <pre><code>config := controller.DefaultConfig()\nconfig.Debug = true\nconfig.QueueCapacity = 131072\nconfig.BatchSize = 2000\nconfig.SizingServiceTime = 20 * time.Millisecond\nconfig.SizingSLO = 200 * time.Millisecond\nconfig.SizingHeadroomPct = 0.15\nctrl := controller.NewController(config)\n</code></pre></p>"},{"location":"reference/types-reference/#controller","title":"Controller","text":"<p>Manages the ECS world and its systems using ark-tools.</p> <p>Fields: - All fields are unexported (internal state)</p> <p>Methods: - LoadMonitors(ctx context.Context, filename string) error - Start() error - Stop() - GetWorld() *ecs.World - PrintShutdownMetrics() - CheckEntityCountAndSwitchQueue()</p> <p>Used by: - Main application entry point - Integration tests</p> <p>Example: <pre><code>config := controller.DefaultConfig()\nctrl := controller.NewController(config)\ndefer ctrl.Stop()\n\nctx := context.Background()\nif err := ctrl.LoadMonitors(ctx, \"monitors.yaml\"); err != nil {\n    log.Fatal(err)\n}\n\nif err := ctrl.Start(); err != nil {\n    log.Fatal(err)\n}\n</code></pre></p>"},{"location":"reference/types-reference/#logger","title":"Logger","text":"<p>Structured logger for component-specific logging with multiple log levels.</p> <p>Fields: - All fields are unexported</p> <p>Methods: - Debug(format string, args ...interface{}) - Info(format string, args ...interface{}) - Warn(format string, args ...interface{}) - Error(format string, args ...interface{}) - LogSystemPerformance(name string, duration time.Duration, count int)</p> <p>When to use: - When creating component-specific loggers - For structured logging with different severity levels</p> <p>Example: <pre><code>logger := controller.NewLogger(\"MyComponent\", true)\nlogger.Info(\"Component started\")\nlogger.Debug(\"Processing item %d\", itemID)\nlogger.Error(\"Failed to process: %v\", err)\n</code></pre></p>"},{"location":"reference/types-reference/#loggeradapter","title":"LoggerAdapter","text":"<p>Adapts the controller loggers to the systems interface.</p> <p>Fields: - logger (interface) - Logger implementation</p> <p>Methods: - Info(format string, args ...interface{}) - Debug(format string, args ...interface{}) - Warn(format string, args ...interface{}) - Error(format string, args ...interface{}) - LogSystemPerformance(name string, duration time.Duration, count int) - LogComponentState(entityID uint32, component string, action string)</p> <p>When to use: - Internal adapter - typically not used directly by applications</p>"},{"location":"reference/types-reference/#metricsaggregator","title":"MetricsAggregator","text":"<p>Aggregates system performance metrics.</p> <p>Fields: - All fields are unexported</p> <p>Methods: - RecordSystemMetric(name string, count int, duration time.Duration) - GetAggregateMetrics() AggregateMetrics</p> <p>When to use: - When collecting and aggregating system performance data - For performance monitoring and analysis</p> <p>Example: <pre><code>metrics := controller.NewMetricsAggregator()\nmetrics.RecordSystemMetric(\"pulse\", 100, 50*time.Millisecond)\naggregate := metrics.GetAggregateMetrics()\nfmt.Printf(\"Total operations: %d\\n\", aggregate.TotalOperations)\n</code></pre></p>"},{"location":"reference/types-reference/#memorymanager","title":"MemoryManager","text":"<p>Monitors and controls application memory usage.</p> <p>Fields: - All fields are unexported</p> <p>Methods: - Start() - Stop() - GetMemoryStats() (alloc, totalAlloc, sys uint64)</p> <p>When to use: - When managing application memory limits - For automatic GC triggering based on memory thresholds</p> <p>Example: <pre><code>memMgr := controller.NewMemoryManager(8, 30) // 8GB max, 30s GC interval\nmemMgr.Start()\ndefer memMgr.Stop()\n</code></pre></p>"},{"location":"reference/types-reference/#recoverysystem","title":"RecoverySystem","text":"<p>Tracks errors and provides circuit breaker functionality.</p> <p>Fields: - All fields are unexported</p> <p>Methods: - RecordError() - ShouldRecover() bool - Reset()</p> <p>When to use: - When implementing error tracking and recovery logic - For circuit breaker patterns</p> <p>Example: <pre><code>recovery := controller.NewRecoverySystem(10, 1*time.Minute)\nif err := doOperation(); err != nil {\n    recovery.RecordError()\n    if recovery.ShouldRecover() {\n        // Trigger recovery logic\n    }\n}\n</code></pre></p>"},{"location":"reference/types-reference/#tracer","title":"Tracer","text":"<p>Distributed tracer for component tracing.</p> <p>Fields: - All fields are unexported</p> <p>Methods: - StartSpan(operation string) TraceSpan - GetSpan(spanID string) (TraceSpan, bool)</p> <p>When to use: - When implementing distributed tracing - For performance analysis and debugging</p> <p>Example: <pre><code>tracer := controller.NewTracer(\"PulseSystem\", true)\nspan := tracer.StartSpan(\"ProcessPulse\")\ndefer span.End()\n// ... do work ...\n</code></pre></p>"},{"location":"reference/types-reference/#tracespan","title":"TraceSpan","text":"<p>Represents a single trace span.</p> <p>Fields: - SpanID (string) - Unique span identifier - Operation (string) - Operation name - StartTime (time.Time) - Span start time - EndTime (time.Time) - Span end time (zero if not ended) - Duration (time.Duration) - Span duration - Component (string) - Component name</p> <p>Methods: - End() - AddMetadata(key string, value interface{})</p> <p>When to use: - Automatically created by Tracer.StartSpan() - For tracking operation timing</p>"},{"location":"reference/types-reference/#package-internalqueue","title":"Package: internal/queue","text":"<p>The queue package provides multiple queue implementations and a dynamic worker pool system. For detailed architecture explanation, see the Architecture Overview document.</p>"},{"location":"reference/types-reference/#queue-interface","title":"Queue (Interface)","text":"<p>Defines the interface for a generic, thread-safe queue system.</p> <p>Methods: - Enqueue(job jobs.Job) error - EnqueueBatch(jobs []interface{}) error - Dequeue() (jobs.Job, error) - DequeueBatch(maxSize int) ([]jobs.Job, error) - Close() - Stats() Stats</p> <p>Implementations: - AdaptiveQueue - WorkivaQueue - HybridQueue - BoundedQueue</p> <p>When to use: - When you need a decoupled queue interface - For dependency injection and testing</p> <p>Example: <pre><code>var q queue.Queue\nconfig := queue.DefaultQueueConfig()\nq, err := queue.NewQueue(config)\nif err != nil {\n    log.Fatal(err)\n}\ndefer q.Close()\n\nerr = q.Enqueue(myJob)\nstats := q.Stats()\nfmt.Printf(\"Queue depth: %d\\n\", stats.QueueDepth)\n</code></pre></p>"},{"location":"reference/types-reference/#stats","title":"Stats","text":"<p>Performance metrics for a queue.</p> <p>Fields: - LastEnqueue (time.Time) - Time of last enqueue operation - LastDequeue (time.Time) - Time of last dequeue operation - AvgQueueTime (time.Duration) - Average time jobs spend in queue - MaxQueueTime (time.Duration) - Maximum time a job spent in queue - Dequeued (int64) - Total jobs dequeued - Dropped (int64) - Total jobs dropped - QueueDepth (int) - Current number of jobs in queue - MaxJobLatency (time.Duration) - Maximum job latency observed - AvgJobLatency (time.Duration) - Average job latency - EnqueueRate (float64) - Enqueue rate (jobs/sec) - DequeueRate (float64) - Dequeue rate (jobs/sec) - Enqueued (int64) - Total jobs enqueued - Capacity (int) - Queue capacity - SampleWindow (time.Duration) - Time window for rate calculations</p> <p>Methods: - None (data struct)</p> <p>When to use: - When monitoring queue performance - For capacity planning and sizing decisions</p> <p>Example: <pre><code>stats := myQueue.Stats()\nfmt.Printf(\"Enqueue rate: %.2f jobs/sec\\n\", stats.EnqueueRate)\nfmt.Printf(\"Queue depth: %d/%d (%.1f%% full)\\n\", \n    stats.QueueDepth, stats.Capacity, \n    100.0*float64(stats.QueueDepth)/float64(stats.Capacity))\nfmt.Printf(\"Avg queue time: %v\\n\", stats.AvgQueueTime)\n</code></pre></p>"},{"location":"reference/types-reference/#queueconfig","title":"QueueConfig","text":"<p>Configuration for queue creation.</p> <p>Fields: - Name (string) - Queue name for logging - Type (QueueType) - Type of queue to create - Capacity (int) - Queue capacity - HybridConfig (HybridQueueConfig) - Configuration for hybrid queues</p> <p>Methods: - None (data struct)</p> <p>When to use: - When creating queues with specific configuration - For customizing queue behavior</p> <p>Example: <pre><code>config := queue.QueueConfig{\n    Name:     \"pulse\",\n    Type:     queue.QueueTypeHybrid,\n    Capacity: 65536,\n    HybridConfig: queue.HybridQueueConfig{\n        RingCapacity: 65536,\n        HeapCapacity: 100000,\n        DropPolicy:   queue.DropPolicyDropNewest,\n    },\n}\nq, err := queue.NewQueue(config)\n</code></pre></p>"},{"location":"reference/types-reference/#queuetype","title":"QueueType","text":"<p>Represents the type of queue to create.</p> <p>Constants: - QueueTypeAdaptive (\"adaptive\") - Adaptive queue that adjusts behavior - QueueTypeWorkiva (\"workiva\") - Workiva ring buffer queue - QueueTypeHybrid (\"hybrid\") - Hybrid ring buffer + heap queue</p> <p>When to use: - When specifying queue type in QueueConfig</p>"},{"location":"reference/types-reference/#dynamicworkerpool","title":"DynamicWorkerPool","text":"<p>Manages a pool of workers that execute jobs from a queue with dynamic scaling.</p> <p>Fields: - All fields are unexported</p> <p>Methods: - Start() - DrainAndStop() - GetRouter() *ResultRouter - Stats() WorkerPoolStats - Pause() - Resume() - ReplaceQueue(newQueue Queue) error</p> <p>When to use: - When you need concurrent job processing with auto-scaling - For processing jobs from queues with result routing</p> <p>Example: <pre><code>config := queue.DefaultWorkerPoolConfig()\nconfig.MinWorkers = 5\nconfig.MaxWorkers = 100\npool, err := queue.NewDynamicWorkerPool(myQueue, config, logger)\nif err != nil {\n    log.Fatal(err)\n}\npool.Start()\ndefer pool.DrainAndStop()\n\nrouter := pool.GetRouter()\ngo func() {\n    for results := range router.PulseResultChan {\n        processResults(results)\n    }\n}()\n</code></pre></p>"},{"location":"reference/types-reference/#workerpoolconfig","title":"WorkerPoolConfig","text":"<p>Configuration for the DynamicWorkerPool.</p> <p>Fields: - MinWorkers (int) - Minimum number of workers - MaxWorkers (int) - Maximum number of workers - AdjustmentInterval (time.Duration) - How often to adjust worker count - ResultBatchSize (int) - Batch size for result processing - ResultBatchTimeout (time.Duration) - Timeout for partial batches - ResultChannelDepth (int) - Buffer size for result channels - TargetQueueLatency (time.Duration) - Target queue latency for scaling - PreAlloc (bool) - Pre-allocate worker goroutines - NonBlocking (bool) - Use non-blocking mode - MaxBlockingTasks (int) - Max tasks to block on (0 = unlimited) - ExpiryDuration (time.Duration) - Worker expiry duration</p> <p>Methods: - None (data struct)</p> <p>When to use: - When creating DynamicWorkerPool instances - For customizing worker pool behavior</p> <p>Example: <pre><code>config := queue.WorkerPoolConfig{\n    MinWorkers:         10,\n    MaxWorkers:         1000,\n    AdjustmentInterval: 5 * time.Second,\n    ResultBatchSize:    512,\n    ResultBatchTimeout: 10 * time.Millisecond,\n    ResultChannelDepth: 2048,\n    TargetQueueLatency: 100 * time.Millisecond,\n    PreAlloc:           false,\n    NonBlocking:        false,\n    ExpiryDuration:     5 * time.Minute,\n}\npool, _ := queue.NewDynamicWorkerPool(myQueue, config, logger)\n</code></pre></p>"},{"location":"reference/types-reference/#workerpoolstats","title":"WorkerPoolStats","text":"<p>Runtime metrics for the dynamic worker pool.</p> <p>Fields: - LastScaleTime (time.Time) - Time of last scaling event - MinWorkers (int) - Minimum worker limit - MaxWorkers (int) - Maximum worker limit - CurrentCapacity (int) - Current worker capacity - RunningWorkers (int) - Currently running workers - WaitingTasks (int) - Tasks waiting for workers - TargetWorkers (int) - Target worker count - TasksSubmitted (int64) - Total tasks submitted - TasksCompleted (int64) - Total tasks completed - ScalingEvents (int64) - Number of scaling events - PendingResults (int) - Results waiting to be processed</p> <p>Methods: - None (data struct)</p> <p>When to use: - When monitoring worker pool performance - For debugging worker pool behavior</p> <p>Example: <pre><code>stats := pool.Stats()\nutilization := 100.0 * float64(stats.RunningWorkers) / float64(stats.CurrentCapacity)\nfmt.Printf(\"Workers: %d/%d (%.1f%% utilized)\\n\", \n    stats.RunningWorkers, stats.CurrentCapacity, utilization)\nfmt.Printf(\"Tasks: %d submitted, %d completed\\n\", \n    stats.TasksSubmitted, stats.TasksCompleted)\n</code></pre></p>"},{"location":"reference/types-reference/#resultrouter","title":"ResultRouter","text":"<p>Routes job results to type-specific channels.</p> <p>Fields: - PulseResultChan (chan []jobs.Result) - Channel for pulse results - InterventionResultChan (chan []jobs.Result) - Channel for intervention results - CodeResultChan (chan []jobs.Result) - Channel for code results</p> <p>Methods: - RouteResults(results []jobs.Result) - Close()</p> <p>When to use: - Automatically used by DynamicWorkerPool - For accessing type-specific result channels</p> <p>Example: <pre><code>router := pool.GetRouter()\n\ngo func() {\n    for results := range router.PulseResultChan {\n        for _, result := range results {\n            processPulseResult(result)\n        }\n    }\n}()\n\ngo func() {\n    for results := range router.InterventionResultChan {\n        for _, result := range results {\n            processInterventionResult(result)\n        }\n    }\n}()\n</code></pre></p>"},{"location":"reference/types-reference/#adaptivequeue","title":"AdaptiveQueue","text":"<p>Adaptive queue that adjusts its behavior based on load.</p> <p>Fields: - All fields are unexported</p> <p>Methods: - Implements Queue interface</p> <p>When to use: - For very large entity counts (&gt;500K monitors) - When load patterns are unpredictable</p> <p>Example: <pre><code>q, err := queue.NewAdaptiveQueue(65536)\nif err != nil {\n    log.Fatal(err)\n}\n</code></pre></p>"},{"location":"reference/types-reference/#hybridqueue","title":"HybridQueue","text":"<p>Combines ring buffer and heap with configurable drop policy.</p> <p>Fields: - All fields are unexported</p> <p>Methods: - Implements Queue interface</p> <p>When to use: - Default queue choice for most workloads - When you need configurable drop policies</p> <p>Example: <pre><code>config := queue.DefaultHybridQueueConfig()\nconfig.DropPolicy = queue.DropPolicyDropNewest\nconfig.RingCapacity = 32768\nconfig.HeapCapacity = 100000\nq, err := queue.NewHybridQueue(config)\n</code></pre></p>"},{"location":"reference/types-reference/#hybridqueueconfig","title":"HybridQueueConfig","text":"<p>Configuration for HybridQueue.</p> <p>Fields: - Name (string) - Queue name for logging - RingCapacity (int) - Ring buffer capacity (must be power of 2) - HeapCapacity (int) - Heap capacity - DropPolicy (DropPolicy) - Policy when both ring and heap are full - SampleWindow (time.Duration) - Window for statistics calculation</p> <p>Methods: - None (data struct)</p> <p>When to use: - When creating HybridQueue instances</p> <p>Example: <pre><code>config := queue.HybridQueueConfig{\n    Name:         \"myqueue\",\n    RingCapacity: 65536,\n    HeapCapacity: 100000,\n    DropPolicy:   queue.DropPolicyDropOldest,\n    SampleWindow: 30 * time.Second,\n}\n</code></pre></p>"},{"location":"reference/types-reference/#droppolicy","title":"DropPolicy","text":"<p>Policy for dropping items when queue is full.</p> <p>Constants: - DropPolicyReject - Reject new items (return error) - DropPolicyDropOldest - Drop oldest items - DropPolicyDropNewest - Drop newest items</p> <p>When to use: - When configuring HybridQueue behavior</p>"},{"location":"reference/types-reference/#boundedqueue","title":"BoundedQueue","text":"<p>Fixed-capacity queue with blocking behavior.</p> <p>Fields: - All fields are unexported</p> <p>Methods: - Implements Queue interface</p> <p>When to use: - When you need strict capacity limits - For testing or simple scenarios</p>"},{"location":"reference/types-reference/#package-internalcontrollercomponents","title":"Package: internal/controller/components","text":""},{"location":"reference/types-reference/#disabled","title":"Disabled","text":"<p>Zero-size tag component marking an entity as disabled.</p> <p>Fields: - None (zero-size struct)</p> <p>Methods: - None</p> <p>When to use: - Added to entities that should be excluded from processing - Using a tag allows filters to exclude disabled entities efficiently at the archetype level</p> <p>Example: <pre><code>// Add Disabled component to an entity\nworld.Add(entity, ecs.C[components.Disabled]())\n\n// Filter excludes disabled entities\nfilter := ecs.NewFilter2[components.MonitorState, components.PulseConfig](world).\n    Without(ecs.C[components.Disabled]())\n</code></pre></p>"},{"location":"reference/types-reference/#monitorstate","title":"MonitorState","text":"<p>Consolidates all monitor state into a single component.</p> <p>Fields: - LastCheckTime (time.Time) - Time of last health check - LastSuccessTime (time.Time) - Time of last successful check - NextCheckTime (time.Time) - Scheduled time for next check - LastError (error) - Last error encountered - Name (string) - Monitor name - PendingCode (string) - Pending code color - ConsecutiveFailures (int) - Number of consecutive failures - PulseFailures (int) - Total pulse failures - InterventionFailures (int) - Total intervention failures - RecoveryStreak (int) - Current recovery streak - VerifyRemaining (int) - Remaining verification checks - Flags (uint32) - Bitfield for state flags</p> <p>State Flag Constants: - StatePulseNeeded (1 &lt;&lt; 1) - StatePulsePending (1 &lt;&lt; 2) - StatePulseFirstCheck (1 &lt;&lt; 3) - StateInterventionNeeded (1 &lt;&lt; 5) - StateInterventionPending (1 &lt;&lt; 6) - StateCodeNeeded (1 &lt;&lt; 7) - StateCodePending (1 &lt;&lt; 8) - StateIncidentOpen (1 &lt;&lt; 9) - StateVerifying (1 &lt;&lt; 10)</p> <p>Methods: - IsPulseNeeded() bool - IsPulsePending() bool - IsPulseFirstCheck() bool - IsInterventionNeeded() bool - IsInterventionPending() bool - IsCodeNeeded() bool - IsCodePending() bool - SetPulseNeeded(needed bool) - SetPulsePending(pending bool) - SetPulseFirstCheck(firstCheck bool) - SetInterventionNeeded(needed bool) - SetInterventionPending(pending bool) - SetCodeNeeded(needed bool) - SetCodePending(pending bool)</p> <p>When to use: - Required component for all monitor entities - Tracks complete monitor state in a single component</p> <p>Example: <pre><code>state := &amp;components.MonitorState{\n    Name:         \"web-server-01\",\n    NextCheckTime: time.Now().Add(60 * time.Second),\n}\nstate.SetPulseNeeded(true)\nworld.Add(entity, ecs.C[components.MonitorState](), state)\n</code></pre></p>"},{"location":"reference/types-reference/#pulseconfig","title":"PulseConfig","text":"<p>Consolidates pulse configuration.</p> <p>Fields: - Config (schema.PulseConfig) - Type-specific pulse configuration - Type (string) - Pulse type (http, tcp, icmp, etc.) - Timeout (time.Duration) - Check timeout - Interval (time.Duration) - Check interval - Retries (int) - Number of retries on failure - UnhealthyThreshold (int) - Failures before marking unhealthy - HealthyThreshold (int) - Successes before marking healthy</p> <p>Methods: - Copy() *PulseConfig - Creates a deep copy</p> <p>When to use: - Attached to entities that require health checking - Defines how and when pulse checks are performed</p> <p>Example: <pre><code>pulseCfg := &amp;components.PulseConfig{\n    Type:               \"http\",\n    Interval:           60 * time.Second,\n    Timeout:            5 * time.Second,\n    Retries:            3,\n    UnhealthyThreshold: 3,\n    HealthyThreshold:   2,\n}\nworld.Add(entity, ecs.C[components.PulseConfig](), pulseCfg)\n</code></pre></p>"},{"location":"reference/types-reference/#interventionconfig","title":"InterventionConfig","text":"<p>Consolidates intervention configuration.</p> <p>Fields: - Target (schema.InterventionTarget) - Intervention target configuration - Action (string) - Action to perform (restart, reboot, etc.) - MaxFailures (int) - Maximum failures before giving up</p> <p>Methods: - Copy() *InterventionConfig - Creates a deep copy</p> <p>When to use: - Attached to entities that support automated remediation - Defines remediation actions</p> <p>Example: <pre><code>intCfg := &amp;components.InterventionConfig{\n    Action:      \"restart\",\n    MaxFailures: 3,\n}\nworld.Add(entity, ecs.C[components.InterventionConfig](), intCfg)\n</code></pre></p>"},{"location":"reference/types-reference/#codeconfig","title":"CodeConfig","text":"<p>Consolidates all code configurations.</p> <p>Fields: - Configs (map[string]*ColorCodeConfig) - Map of color to configuration</p> <p>Methods: - Copy() *CodeConfig - Creates a deep copy</p> <p>When to use: - Attached to entities that require alerting - Supports multiple code colors per monitor</p> <p>Example: <pre><code>codeConfig := &amp;components.CodeConfig{\n    Configs: map[string]*components.ColorCodeConfig{\n        \"red\": {\n            Notify:   \"pagerduty\",\n            Dispatch: true,\n        },\n        \"yellow\": {\n            Notify:   \"slack\",\n            Dispatch: false,\n        },\n    },\n}\nworld.Add(entity, ecs.C[components.CodeConfig](), codeConfig)\n</code></pre></p>"},{"location":"reference/types-reference/#colorcodeconfig","title":"ColorCodeConfig","text":"<p>Configuration for a specific code color.</p> <p>Fields: - Config (schema.CodeNotification) - Notification configuration - Notify (string) - Notification target - MaxFailures (int) - Max failures before escalation - Dispatch (bool) - Whether to dispatch immediately</p> <p>Methods: - Copy() *ColorCodeConfig - Creates a deep copy</p> <p>When to use: - Used within CodeConfig map</p>"},{"location":"reference/types-reference/#codestatus","title":"CodeStatus","text":"<p>Consolidates all code status.</p> <p>Fields: - Status (map[string]*ColorCodeStatus) - Map of color to status</p> <p>Methods: - Copy() *CodeStatus - Creates a deep copy</p> <p>When to use: - Tracks status of code notifications per color</p>"},{"location":"reference/types-reference/#colorcodestatus","title":"ColorCodeStatus","text":"<p>Status for a specific code color.</p> <p>Fields: - LastAlertTime (time.Time) - Time of last alert - LastSuccessTime (time.Time) - Time of last successful notification - LastError (error) - Last error encountered - LastStatus (string) - Last status (\"success\" or \"failed\") - ConsecutiveFailures (int) - Consecutive notification failures</p> <p>Methods: - SetSuccess(t time.Time) - SetFailure(err error) - Copy() *ColorCodeStatus - Creates a deep copy</p> <p>When to use: - Used within CodeStatus map</p>"},{"location":"reference/types-reference/#jobstorage","title":"JobStorage","text":"<p>Consolidates all job storage.</p> <p>Fields: - PulseJob (jobs.Job) - Pulse job - InterventionJob (jobs.Job) - Intervention job - CodeJobs (map[string]jobs.Job) - Code jobs by color</p> <p>Methods: - Copy() *JobStorage - Creates a deep copy</p> <p>When to use: - Stores pre-created jobs for an entity - Added before jobs are enqueued</p>"},{"location":"reference/types-reference/#pulseresult","title":"PulseResult","text":"<p>Result component for pulse jobs.</p> <p>Fields: - Result (jobs.Result) - Job result</p> <p>Methods: - None</p> <p>When to use: - Added by worker pool result router - Removed by BatchPulseResultSystem after processing</p>"},{"location":"reference/types-reference/#interventionresult","title":"InterventionResult","text":"<p>Result component for intervention jobs.</p> <p>Fields: - Result (jobs.Result) - Job result</p> <p>Methods: - None</p> <p>When to use: - Added by worker pool result router - Removed by BatchInterventionResultSystem after processing</p>"},{"location":"reference/types-reference/#coderesult","title":"CodeResult","text":"<p>Result component for code notification jobs.</p> <p>Fields: - Result (jobs.Result) - Job result</p> <p>Methods: - None</p> <p>When to use: - Added by worker pool result router - Removed by BatchCodeResultSystem after processing</p>"},{"location":"reference/types-reference/#package-internalloaderstreaming","title":"Package: internal/loader/streaming","text":""},{"location":"reference/types-reference/#streamingloader","title":"StreamingLoader","text":"<p>Orchestrates the streaming loading process.</p> <p>Fields: - All fields are unexported</p> <p>Methods: - Load(ctx context.Context) (*LoadingStats, error)</p> <p>When to use: - When loading monitor configurations from large files - Supports streaming for memory-efficient loading</p> <p>Example: <pre><code>config := streaming.DefaultStreamingConfig()\nloader := streaming.NewStreamingLoader(\"monitors.yaml\", world, config)\nstats, err := loader.Load(context.Background())\nif err != nil {\n    log.Fatal(err)\n}\nfmt.Printf(\"Loaded %d monitors\\n\", stats.TotalEntities)\n</code></pre></p>"},{"location":"reference/types-reference/#streamingconfig","title":"StreamingConfig","text":"<p>Configuration for streaming loader.</p> <p>Fields: - ParseBatchSize (int) - Batch size for parsing - ParseBufferSize (int) - Buffer size for file reading - MaxParseMemory (int64) - Maximum memory for parsing - EntityBatchSize (int) - Batch size for entity creation - PreAllocateCount (int) - Number of entities to pre-allocate - MaxWorkers (int) - Maximum concurrent workers - ProgressInterval (time.Duration) - Progress reporting interval - GCInterval (time.Duration) - GC interval during loading - MemoryLimit (int64) - Memory limit - StrictUnknownFields (bool) - Error on unknown fields - JSONUseNumber (bool) - Use number type for JSON numbers</p> <p>Methods: - None (data struct)</p> <p>When to use: - Configuring StreamingLoader behavior</p> <p>Example: <pre><code>config := streaming.StreamingConfig{\n    ParseBatchSize:   20000,\n    EntityBatchSize:  10000,\n    PreAllocateCount: 1000000,\n    ProgressInterval: 1 * time.Second,\n}\n</code></pre></p>"},{"location":"reference/types-reference/#loadingstats","title":"LoadingStats","text":"<p>Comprehensive loading statistics.</p> <p>Fields: - TotalEntities (int64) - Total entities loaded - LoadingTime (time.Duration) - Total loading time - ParseRate (float64) - Parse rate (entities/sec) - CreationRate (float64) - Creation rate (entities/sec) - MemoryUsage (int64) - Memory used during loading - GCCount (int) - Number of GC cycles - PulseRate (float64) - Expected pulse arrival rate (jobs/sec)</p> <p>Methods: - None (data struct)</p> <p>When to use: - Returned by StreamingLoader.Load() - For analyzing loading performance</p>"},{"location":"reference/types-reference/#streamingentitycreator","title":"StreamingEntityCreator","text":"<p>Handles batch entity creation for Ark ECS.</p> <p>Fields: - All fields are unexported</p> <p>Methods: - ProcessBatches(ctx context.Context, batchChan &lt;-chan MonitorBatch, progressChan chan&lt;- EntityProgress) error - GetStats() (entitiesCreated int64, batchesProcessed int64, rate float64) - PulseRate() float64</p> <p>When to use: - Used internally by StreamingLoader - Can be used standalone for custom loading</p>"},{"location":"reference/types-reference/#entitycreationconfig","title":"EntityCreationConfig","text":"<p>Configuration for entity creation.</p> <p>Fields: - ProgressChan (chan&lt;- EntityProgress) - Channel for progress updates - BatchSize (int) - Batch size - PreAllocate (int) - Number of entities to pre-allocate</p> <p>Methods: - None (data struct)</p> <p>When to use: - Configuring StreamingEntityCreator</p>"},{"location":"reference/types-reference/#monitorbatch","title":"MonitorBatch","text":"<p>Represents a batch of monitors read from a file.</p> <p>Fields: - Monitors ([]schema.Monitor) - Monitors in batch - BatchID (int) - Batch identifier - Offset (int64) - File offset</p> <p>Methods: - None (data struct)</p> <p>When to use: - Internal data structure for streaming</p>"},{"location":"reference/types-reference/#parseconfig","title":"ParseConfig","text":"<p>Configuration for streaming parsers.</p> <p>Fields: - ProgressChan (chan&lt;- Progress) - Channel for progress updates - BatchSize (int) - Parse batch size - BufferSize (int) - File buffer size - MaxMemory (int64) - Maximum memory for parsing - StrictUnknownFields (bool) - Error on unknown fields - JSONUseNumber (bool) - Use number type for JSON</p> <p>Methods: - None (data struct)</p> <p>When to use: - Configuring streaming parsers</p>"},{"location":"reference/types-reference/#progress","title":"Progress","text":"<p>Represents parsing progress.</p> <p>Fields: - EntitiesProcessed (int64) - Entities processed - TotalBytes (int64) - Total file bytes - ProcessedBytes (int64) - Bytes processed - Percentage (float64) - Completion percentage - Rate (float64) - Processing rate (entities/sec) - EstimatedRemaining (time.Duration) - Estimated remaining time</p> <p>Methods: - None (data struct)</p> <p>When to use: - Progress monitoring during loading</p>"},{"location":"reference/types-reference/#entityprogress","title":"EntityProgress","text":"<p>Represents entity creation progress.</p> <p>Fields: - EntitiesCreated (int64) - Entities created - BatchesProcessed (int64) - Batches processed - Rate (float64) - Creation rate (entities/sec) - MemoryUsage (int64) - Current memory usage</p> <p>Methods: - None (data struct)</p> <p>When to use: - Progress monitoring during entity creation</p>"},{"location":"reference/types-reference/#package-internalcontrollersystems","title":"Package: internal/controller/systems","text":""},{"location":"reference/types-reference/#logger-interface","title":"Logger (Interface)","text":"<p>Interface for system loggers.</p> <p>Methods: - Info(format string, args ...interface{}) - Debug(format string, args ...interface{}) - Warn(format string, args ...interface{}) - Error(format string, args ...interface{}) - LogSystemPerformance(name string, duration time.Duration, count int)</p> <p>When to use: - Interface for injecting loggers into systems</p>"},{"location":"reference/types-reference/#statelogger","title":"StateLogger","text":"<p>Tracks entity state transitions.</p> <p>Fields: - All fields are unexported</p> <p>Methods: - LogStateChange(entityID uint32, component string, action string) - LogSystemMetrics(systemName string, processed int, duration time.Duration)</p> <p>When to use: - Debugging state transitions - Performance analysis</p>"},{"location":"reference/types-reference/#memoryconfig","title":"MemoryConfig","text":"<p>Configuration for memory-efficient system.</p> <p>Fields: - MaxEntities (int) - Maximum entities - PreAllocate (bool) - Pre-allocate memory</p> <p>Methods: - None (data struct)</p> <p>When to use: - Configuring MemoryEfficientSystem</p>"},{"location":"reference/types-reference/#memorystats","title":"MemoryStats","text":"<p>Memory statistics.</p> <p>Fields: - AllocatedEntities (int) - Allocated entities - ActiveEntities (int) - Active entities - MemoryUsage (int64) - Memory usage in bytes</p> <p>Methods: - None (data struct)</p> <p>When to use: - Returned by MemoryEfficientSystem for monitoring</p>"},{"location":"reference/types-reference/#errnopulsejob","title":"ErrNoPulseJob","text":"<p>Error when no pulse job is found for an entity.</p> <p>Fields: - EntityID (uint32) - Entity ID</p> <p>Methods: - Error() string</p> <p>When to use: - Error handling in pulse systems</p>"},{"location":"reference/types-reference/#errpulsejobtimeout","title":"ErrPulseJobTimeout","text":"<p>Error when pulse job times out.</p> <p>Fields: - EntityID (uint32) - Entity ID - Timeout (time.Duration) - Timeout duration</p> <p>Methods: - Error() string</p> <p>When to use: - Error handling in pulse systems</p>"},{"location":"tutorials/","title":"Tutorials","text":"<p>Learning-oriented guides for newcomers</p>"},{"location":"tutorials/#available-guides","title":"Available Guides","text":"<p>This section contains tutorials documentation following the Diataxis framework.</p> <p>Tutorials are learning-oriented and help newcomers get started: - Take the reader through a process step by step - Focus on learning by doing - Ensure the reader succeeds in accomplishing something - Build confidence through success</p>"},{"location":"tutorials/#contents","title":"Contents","text":"<ul> <li>Example: getting-started.md</li> </ul>"},{"location":"tutorials/getting-started/","title":"Getting Started","text":"<p>This guide will walk you through the process of setting up and running CPRA on your local machine.</p>"},{"location":"tutorials/getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Go 1.25 or later</li> <li>Docker (optional, for running in a container)</li> </ul>"},{"location":"tutorials/getting-started/#building-from-source","title":"Building from Source","text":"<ol> <li> <p>Clone the repository:     <pre><code>git clone https://github.com/ziad/cpra.git\ncd cpra\n</code></pre></p> </li> <li> <p>Build the application:     <pre><code>go build .\n</code></pre></p> </li> </ol>"},{"location":"tutorials/getting-started/#running-the-application","title":"Running the Application","text":"<p>To run the application, you need to provide a YAML file with the monitor configurations. An example file is provided at <code>mock-servers/test_10k.yaml</code>.</p> <pre><code>./cpra --yaml mock-servers/test_10k.yaml\n</code></pre> <p>You should see output indicating that the controller is starting and loading the monitors.</p>"},{"location":"tutorials/getting-started/#running-with-docker","title":"Running with Docker","text":"<p>You can also run the application in a Docker container.</p> <ol> <li> <p>Build the Docker image using the provided Dockerfile:     <pre><code>docker build -f docker/Dockerfile -t cpra .\n</code></pre></p> <p>Note: If the build fails due to a missing <code>samples/</code> directory referenced in the Dockerfile, either create <code>cpra/samples</code> with your YAML files, or remove the <code>COPY samples samples</code> line from <code>docker/Dockerfile</code> before building.</p> </li> <li> <p>Run the container with a YAML file mounted (example uses the 10k mock monitors):     <pre><code>docker run -it --rm \\\n  -v $(pwd)/mock-servers/test_10k.yaml:/app/monitors.yaml \\\n  cpra \\\n  ./cpra --yaml /app/monitors.yaml\n</code></pre></p> </li> </ol>"},{"location":"tutorials/getting-started/#whats-next","title":"What's Next?","text":"<p>Now that you have CPRA up and running, you can start to explore its features:</p> <ul> <li>Create your own monitor configuration file.</li> <li>Explore the different types of pulses, interventions, and codes.</li> <li>Learn more about the architecture of CPRA in our Architecture Overview.</li> </ul>"},{"location":"tutorials/quickstart/","title":"Quickstart","text":"<p>This tutorial provides the fastest way to get CPRA running on your local machine using Docker. In just a few minutes, you will build the application, run it with a sample configuration of 10,000 monitors, and observe the system's core functionality.</p> <p>This approach is ideal for a first-time evaluation of CPRA, as it requires no Go environment setup.</p>"},{"location":"tutorials/quickstart/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker: You must have Docker installed and the Docker daemon running. You can find installation instructions at the official Docker website.</li> <li>Git: You will need Git to clone the project repository.</li> </ul>"},{"location":"tutorials/quickstart/#step-1-clone-the-repository","title":"Step 1: Clone the Repository","text":"<p>First, open your terminal and clone the <code>ziad-hsn/cpra</code> repository to your local machine.</p> <pre><code>$ git clone https://github.com/ziad-hsn/cpra.git\n$ cd cpra\n</code></pre> <p>This will download the project source code, including the Dockerfile and the sample monitor configurations we will use.</p>"},{"location":"tutorials/quickstart/#step-2-build-the-docker-image","title":"Step 2: Build the Docker Image","text":"<p>Next, use the provided Dockerfile to build a container image for CPRA. This command compiles the Go application inside a controlled Docker environment and packages it into a lightweight image named <code>cpra:latest</code>.</p> <pre><code>$ docker build -f docker/Dockerfile -t cpra:latest .\n</code></pre>"},{"location":"tutorials/quickstart/#step-3-run-the-cpra-container","title":"Step 3: Run the CPRA Container","text":"<p>Now, run the container you just built. This command starts CPRA and uses a volume mount (<code>-v</code>) to provide the <code>test_10k.yaml</code> file from your local machine as the monitor configuration inside the container.</p> <pre><code>$ docker run -it --rm \\\n  -v $(pwd)/mock-servers/test_10k.yaml:/app/monitors.yaml \\\n  cpra:latest \\\n  ./cpra --yaml /app/monitors.yaml\n</code></pre>"},{"location":"tutorials/quickstart/#step-4-analyze-the-output","title":"Step 4: Analyze the Output","text":"<p>If successful, you will see log messages indicating that the controller has started, loaded the 10,000 monitors, and dynamically scaled its worker pool to meet the default performance targets.</p> <pre><code># Expected Log Output\n\nStarting CPRA Optimized Controller for 1M Monitors\nProfiling server listening at http://localhost:6060/debug/pprof/\nLoading monitors from mock-servers/test_10k.yaml...\nMonitor loading completed in 1.2s\n[INFO] Controller started successfully\n[INFO] Pulse pipeline processing 10,000 monitors\n[INFO] Worker pool scaled to 143 workers (target SLO: 100ms)\n</code></pre> <p>This output confirms that: 1.  The application started correctly. 2.  It successfully parsed the YAML configuration file. 3.  The Pulse Pipeline is active and processing checks. 4.  The dynamic scaling feature has calculated and provisioned the optimal number of workers (143 in this example) to handle the load while respecting the 100ms Service Level Objective (SLO).</p>"},{"location":"tutorials/quickstart/#next-steps","title":"Next Steps","text":"<p>Congratulations! You have successfully started CPRA. To learn how to define your own health checks, proceed to the next tutorial:</p> <ul> <li>Your First Custom Monitor</li> </ul>"},{"location":"tutorials/your-first-monitor/","title":"Your First Custom Monitor","text":"<p>This tutorial walks you through creating a single, comprehensive monitor that utilizes all three of CPRA's processing pipelines: Pulse, Intervention, and Code.</p>"},{"location":"tutorials/your-first-monitor/#monitor-structure","title":"Monitor Structure","text":"<p>A CPRA monitor is defined in a YAML file and consists of three main sections:</p> <ol> <li><code>pulse</code>: Defines the health check (e.g., HTTP GET, TCP ping).</li> <li><code>intervention</code>: Defines the automated action to take on failure (e.g., run a script, restart a service).</li> <li><code>codes</code>: Defines the alerting policy (e.g., send an alert after 3 failures).</li> </ol>"},{"location":"tutorials/your-first-monitor/#step-1-create-the-monitor-yaml","title":"Step 1: Create the Monitor YAML","text":"<p>Create a new file named <code>my-monitor.yaml</code> and add the following content. This monitor checks an HTTP endpoint every 30 seconds. If it fails 3 times, it attempts an intervention, and if the intervention fails, it sends an alert.</p> <pre><code>monitors:\n  - name: \"critical-api-health-check\"\n    enabled: true\n    pulse:\n      type: http\n      interval: 30s\n      timeout: 5s\n      unhealthy_threshold: 3 # Fail after 3 consecutive failures\n      config:\n        method: GET\n        url: http://my-critical-api.internal/health\n        expected_status: 200\n    intervention:\n      action: script\n      max_failures: 1 # Trigger intervention on the first failure after threshold\n      config:\n        path: /usr/local/bin/restart_api.sh\n        args: [\"--force\"]\n    codes:\n      # The 'Red' code is typically for critical alerts\n      Red:\n        dispatch: failure\n        notify: webhook\n        config:\n          url: https://pagerduty.com/api/v2/alerts\n          payload:\n            service: \"critical-api\"\n            status: \"down\"\n</code></pre>"},{"location":"tutorials/your-first-monitor/#step-2-understand-the-pipeline-flow","title":"Step 2: Understand the Pipeline Flow","text":"<p>When this monitor is loaded, it will follow this flow:</p> <ol> <li>Pulse Pipeline: Executes the <code>http</code> check every 30 seconds.</li> <li>Failure Condition: If the check fails, the <code>unhealthy_threshold</code> counter increments.</li> <li>Intervention Trigger: After 3 consecutive failures, the Intervention Pipeline is triggered. It executes the <code>/usr/local/bin/restart_api.sh</code> script.</li> <li>Code Trigger: If the Intervention fails, or if the Pulse check continues to fail after the Intervention, the Code Pipeline is triggered, dispatching the <code>Red</code> alert via the configured webhook.</li> </ol>"},{"location":"tutorials/your-first-monitor/#step-3-run-with-your-monitor","title":"Step 3: Run with Your Monitor","text":"<p>To run CPRA with your new monitor, use the same command as the Quickstart, but point to your new file:</p> <pre><code>$ docker run -it --rm \\\n  -v $(pwd)/my-monitor.yaml:/app/monitors.yaml \\\n  cpra:latest \\\n  ./cpra --yaml /app/monitors.yaml\n</code></pre>"},{"location":"tutorials/your-first-monitor/#next-steps","title":"Next Steps","text":"<ul> <li>Monitor Configuration Schema: Explore all available options for <code>pulse</code>, <code>intervention</code>, and <code>codes</code>.</li> <li>Architecture Overview: Understand the ECS core that powers this high-performance flow.</li> </ul>"}]}